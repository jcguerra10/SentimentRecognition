{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Clean of Text Data\n",
    "El siguiente notebook presenta el proceso de limpieza de los datos de texto"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-16T15:02:36.887749Z",
     "end_time": "2023-05-16T15:02:36.920211Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_SRC_PATH = '../data/text/cleaned/reduced_final.csv'\n",
    "DATA_DST_PATH = '../data/text/cleaned/reduced_final_eng_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import langid"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-16T15:02:36.904582Z",
     "end_time": "2023-05-16T15:02:36.951460Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def remove_long_sentences(df: pd.DataFrame, max_len=300) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes long strings from dataframe\n",
    "    :param df: The dataframe that has a column named 'text' which contains the strings to remove\n",
    "    :param max_len: The length of the biggest string allowed\n",
    "    :return: The dataframe with the longest strings removed\n",
    "    \"\"\"\n",
    "    print('-'*20, '\\nRemoving long sentences')\n",
    "    df['len'] = df['text'].apply(len)\n",
    "    df = df[ (df['len'] <= max_len)]\n",
    "    df.drop(columns=['len'])\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-16T15:02:36.920211Z",
     "end_time": "2023-05-16T15:02:36.967089Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_lang(sentence: str):\n",
    "    lang = langid.classify(sentence)[0]\n",
    "    return lang\n",
    "\n",
    "def remove_non_lang_sentences(df: pd.DataFrame, lang='en') -> pd.DataFrame:\n",
    "    print('-'*20, '\\nRemoving non eng sentences')\n",
    "    df['lang'] = df['text'].apply(get_lang)\n",
    "    df = df[ (df['lang'] == lang) ]\n",
    "    df.drop(columns=['lang'])\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-16T15:02:36.935834Z",
     "end_time": "2023-05-16T15:02:36.967089Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame):\n",
    "    print('-'*20, '\\nDelete nans')\n",
    "    df.dropna(inplace=True)\n",
    "    df = remove_long_sentences(df)\n",
    "    df = remove_non_lang_sentences(df)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-16T15:02:36.967089Z",
     "end_time": "2023-05-16T15:02:37.013962Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- \n",
      "Delete nans\n",
      "-------------------- \n",
      "Removing long sentences\n",
      "-------------------- \n",
      "Removing non eng sentences\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(DATA_SRC_PATH)\n\u001B[1;32m----> 2\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mclean_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[8], line 5\u001B[0m, in \u001B[0;36mclean_data\u001B[1;34m(df)\u001B[0m\n\u001B[0;32m      3\u001B[0m df\u001B[38;5;241m.\u001B[39mdropna(inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      4\u001B[0m df \u001B[38;5;241m=\u001B[39m remove_long_sentences(df)\n\u001B[1;32m----> 5\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mremove_non_lang_sentences\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "Cell \u001B[1;32mIn[7], line 7\u001B[0m, in \u001B[0;36mremove_non_lang_sentences\u001B[1;34m(df, lang)\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mremove_non_lang_sentences\u001B[39m(df: pd\u001B[38;5;241m.\u001B[39mDataFrame, lang\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124men\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame:\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m20\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mRemoving non eng sentences\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m     df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlang\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mget_lang\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     df \u001B[38;5;241m=\u001B[39m df[ (df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlang\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m lang) ]\n\u001B[0;32m      9\u001B[0m     df\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlang\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[1;32m~\\.conda\\envs\\SentimentRecognition\\lib\\site-packages\\pandas\\core\\series.py:4771\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4661\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4662\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4663\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4666\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4667\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4668\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4669\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4670\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4769\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4770\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\SentimentRecognition\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[0;32m   1122\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[1;32m-> 1123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\SentimentRecognition\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1172\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1173\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m-> 1174\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1175\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1176\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1178\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1181\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1182\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\.conda\\envs\\SentimentRecognition\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn[7], line 2\u001B[0m, in \u001B[0;36mget_lang\u001B[1;34m(sentence)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_lang\u001B[39m(sentence: \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m----> 2\u001B[0m     lang \u001B[38;5;241m=\u001B[39m \u001B[43mlangid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclassify\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentence\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lang\n",
      "File \u001B[1;32m~\\.conda\\envs\\SentimentRecognition\\lib\\site-packages\\langid\\langid.py:107\u001B[0m, in \u001B[0;36mclassify\u001B[1;34m(instance)\u001B[0m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m identifier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    105\u001B[0m   load_model()\n\u001B[1;32m--> 107\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43midentifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclassify\u001B[49m\u001B[43m(\u001B[49m\u001B[43minstance\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\SentimentRecognition\\lib\\site-packages\\langid\\langid.py:295\u001B[0m, in \u001B[0;36mLanguageIdentifier.classify\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    292\u001B[0m \u001B[38;5;124;03mClassify an instance.\u001B[39;00m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    294\u001B[0m fv \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance2fv(text)\n\u001B[1;32m--> 295\u001B[0m probs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm_probs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnb_classprobs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfv\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    296\u001B[0m cl \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(probs)\n\u001B[0;32m    297\u001B[0m conf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(probs[cl])\n",
      "File \u001B[1;32m~\\.conda\\envs\\SentimentRecognition\\lib\\site-packages\\langid\\langid.py:287\u001B[0m, in \u001B[0;36mLanguageIdentifier.nb_classprobs\u001B[1;34m(self, fv)\u001B[0m\n\u001B[0;32m    285\u001B[0m pdc \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(fv,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnb_ptc)\n\u001B[0;32m    286\u001B[0m \u001B[38;5;66;03m# compute the partial log-probability of the document in each class\u001B[39;00m\n\u001B[1;32m--> 287\u001B[0m pd \u001B[38;5;241m=\u001B[39m \u001B[43mpdc\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnb_pc\u001B[49m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pd\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_SRC_PATH)\n",
    "data = clean_data(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "filepath = Path(DATA_DST_PATH)\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "data.to_csv(filepath, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
