{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 16:57:12.804485: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-01 16:57:13.368893: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/yonosoysantiago/miniconda3/envs/tf211_conda/lib/:/home/yonosoysantiago/miniconda3/envs/tf211_conda/lib/\n",
      "2023-05-01 16:57:13.368951: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/yonosoysantiago/miniconda3/envs/tf211_conda/lib/:/home/yonosoysantiago/miniconda3/envs/tf211_conda/lib/\n",
      "2023-05-01 16:57:13.368957: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     tiffanylue i know i was listenin to bad habit...\n",
       "1    layin n bed with a headache ughhhh waitin on y...\n",
       "2                      funeral ceremony gloomy friday \n",
       "3                 wants to hang out with friends soon \n",
       "4     dannycastillo we want to trade with someone w...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../../data/cleaned/out.csv\")\n",
    "\n",
    "# Text preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yonosoysantiago/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    tiffanylue know listenin bad habit earlier sta...\n",
       "1              layin n bed headache ughhhh waitin call\n",
       "2                       funeral ceremony gloomy friday\n",
       "3                              wants hang friends soon\n",
       "4    dannycastillo want trade someone houston ticke...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['text'] = df['text'].apply(remove_stopwords)\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenized_texts = [text.split() for text in df['text']]\n",
    "word2vec = Word2Vec(tokenized_texts, vector_size=100, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "    words = text.split()\n",
    "    word_vectors = [word2vec.wv[word] for word in words if word in word2vec.wv]\n",
    "    if not word_vectors:\n",
    "        return np.zeros(word2vec.vector_size).tolist()\n",
    "    return np.mean(word_vectors, axis=0).tolist()\n",
    "\n",
    "\n",
    "df['vector'] = df['text'].apply(text_to_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yonosoysantiago/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_labels = encoder.fit_transform(df['label'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65989, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tiffanylue know listenin bad habit earlier sta...</td>\n",
       "      <td>[-0.0985688716173172, 0.45782729983329773, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>layin n bed headache ughhhh waitin call</td>\n",
       "      <td>[-0.27400386333465576, 0.4046027362346649, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>funeral ceremony gloomy friday</td>\n",
       "      <td>[-0.17208629846572876, 0.18125255405902863, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wants hang friends soon</td>\n",
       "      <td>[-0.37086427211761475, 0.8183702230453491, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>dannycastillo want trade someone houston ticke...</td>\n",
       "      <td>[-0.18290771543979645, 0.665810227394104, -0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  tiffanylue know listenin bad habit earlier sta...   \n",
       "1      0            layin n bed headache ughhhh waitin call   \n",
       "2      0                     funeral ceremony gloomy friday   \n",
       "3      1                            wants hang friends soon   \n",
       "4      6  dannycastillo want trade someone houston ticke...   \n",
       "\n",
       "                                              vector  \n",
       "0  [-0.0985688716173172, 0.45782729983329773, -0....  \n",
       "1  [-0.27400386333465576, 0.4046027362346649, -0....  \n",
       "2  [-0.17208629846572876, 0.18125255405902863, -0...  \n",
       "3  [-0.37086427211761475, 0.8183702230453491, -0....  \n",
       "4  [-0.18290771543979645, 0.665810227394104, -0.1...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_tensor(arg):\n",
    "    arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
    "    return arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([np.array(vec) for vec in df['vector'].to_numpy()], dtype=np.float32)\n",
    "y = encoded_labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (52791, 100)\n",
      "y_train shape: (52791, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73343/3247501290.py:5: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import RandomSearch, HyperParameters\n",
      "2023-05-01 16:57:19.958443: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:19.958648: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:19.962580: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:19.962777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:19.962928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:19.963071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:19.963399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-01 16:57:20.071978: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:20.072209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:20.072357: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:20.072491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:20.072623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:20.072754: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:20.805816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:20.806028: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:20.806180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:20.806317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:20.806452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:20.806564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5526 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-05-01 16:57:20.806817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 16:57:20.806944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 2616 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:06:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "lstm_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
      "lstm_dropout (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.001, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Embedding, Lambda, LSTM, Flatten, Dense, Input, Dropout, Bidirectional, GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from kerastuner import RandomSearch, HyperParameters\n",
    "\n",
    "def build_model(hp):\n",
    "\n",
    "    # Model parameters\n",
    "    input_dim = 100  # Word2Vec vector size\n",
    "    output_dim = 7   # Number of sentiment labels\n",
    "\n",
    "    # # Build the LSTM model\n",
    "    # model = Sequential()\n",
    "    # model.add(Embedding(input_dim=input_dim+1, output_dim=input_dim, input_length=input_dim))\n",
    "    # model.add(LSTM(hidden_units))\n",
    "    # model.add(Dense(output_dim, activation='softmax'))\n",
    "    model = Sequential()\n",
    "\n",
    "    # Embedding\n",
    "    model.add(Embedding(input_dim=input_dim+1, output_dim=output_dim, input_length=input_dim))\n",
    "\n",
    "    # Hiperparámetros para LSTM\n",
    "    lstm_units = hp.Int(\"lstm_units\", min_value=32, max_value=256, step=32)\n",
    "    lstm_dropout = hp.Float(\"lstm_dropout\", min_value=0.1, max_value=0.5, step=0.1)\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(lstm_units, dropout=lstm_dropout)))\n",
    "\n",
    "    # Salida del modelo\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Hiperparámetros para el optimizador (En otras pruebas se vio que Adam era el mejor)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-3, sampling=\"LOG\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define el objeto de búsqueda aleatoria\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=20,  # Número de modelos a probar\n",
    "    executions_per_trial=1,\n",
    "    directory='./saved/fine_tuned/',\n",
    "    project_name='HP_LSTM-Word2Vec-OHE'\n",
    ")\n",
    "\n",
    "# Resumen de la búsqueda\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-5)\n",
    "cp = ModelCheckpoint('saved/', save_best_only=True)\n",
    "\n",
    "callbacks = [cp, early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 Complete [00h 01m 25s]\n",
      "val_accuracy: 0.2140151560306549\n",
      "\n",
      "Best val_accuracy So Far: 0.24715909361839294\n",
      "Total elapsed time: 00h 09m 47s\n",
      "\n",
      "Search: Running Trial #9\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "224               |64                |lstm_units\n",
      "0.5               |0.1               |lstm_dropout\n",
      "1.645e-05         |2.21e-05          |learning_rate\n",
      "\n",
      "Epoch 1/10\n",
      " 6/12 [==============>...............] - ETA: 1s - loss: 1.9456 - accuracy: 0.1656WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0730s vs `on_train_batch_end` time: 0.0836s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0730s vs `on_train_batch_end` time: 0.0836s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - ETA: 0s - loss: 1.9452 - accuracy: 0.1798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 12s 898ms/step - loss: 1.9452 - accuracy: 0.1798 - val_loss: 1.9442 - val_accuracy: 0.2117 - lr: 1.6450e-05\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.9435 - accuracy: 0.2158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 10s 874ms/step - loss: 1.9435 - accuracy: 0.2158 - val_loss: 1.9424 - val_accuracy: 0.2534 - lr: 1.6450e-05\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.9417 - accuracy: 0.2333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 10s 884ms/step - loss: 1.9417 - accuracy: 0.2333 - val_loss: 1.9406 - val_accuracy: 0.2472 - lr: 1.6450e-05\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.9398 - accuracy: 0.2451"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 10s 893ms/step - loss: 1.9398 - accuracy: 0.2451 - val_loss: 1.9386 - val_accuracy: 0.2472 - lr: 1.6450e-05\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.9377 - accuracy: 0.2462"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 10s 850ms/step - loss: 1.9377 - accuracy: 0.2462 - val_loss: 1.9363 - val_accuracy: 0.2472 - lr: 1.6450e-05\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.9353 - accuracy: 0.2467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 10s 906ms/step - loss: 1.9353 - accuracy: 0.2467 - val_loss: 1.9337 - val_accuracy: 0.2472 - lr: 1.6450e-05\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.9325 - accuracy: 0.2467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 10s 864ms/step - loss: 1.9325 - accuracy: 0.2467 - val_loss: 1.9305 - val_accuracy: 0.2472 - lr: 1.6450e-05\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.9290 - accuracy: 0.2467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 10s 868ms/step - loss: 1.9290 - accuracy: 0.2467 - val_loss: 1.9264 - val_accuracy: 0.2472 - lr: 1.6450e-05\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.9243 - accuracy: 0.2467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 10s 872ms/step - loss: 1.9243 - accuracy: 0.2467 - val_loss: 1.9208 - val_accuracy: 0.2472 - lr: 1.6450e-05\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.9176 - accuracy: 0.2467"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m BATCH_SIZE\u001b[39m=\u001b[39m\u001b[39m4096\u001b[39m\n\u001b[0;32m----> 2\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(X_train, y_train,\n\u001b[1;32m      3\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m                     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m                     batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE,\n\u001b[1;32m      6\u001b[0m                     callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[1;32m      8\u001b[0m best_hp_random \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_hyperparameters(num_trials\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMejores hiperparámetros encontrados:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:230\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:270\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m    269\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    271\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[1;32m    272\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 235\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[1;32m    237\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[1;32m    238\u001b[0m     ):\n\u001b[1;32m    239\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    240\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    241\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    243\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    251\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:287\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    286\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 287\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    289\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    290\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:214\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    213\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 214\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[1;32m    216\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m )\n\u001b[1;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py:144\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/engine/training.py:1712\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1708\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1709\u001b[0m     }\n\u001b[1;32m   1710\u001b[0m     epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n\u001b[0;32m-> 1712\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_epoch_end(epoch, epoch_logs)\n\u001b[1;32m   1713\u001b[0m training_logs \u001b[39m=\u001b[39m epoch_logs\n\u001b[1;32m   1714\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/callbacks.py:454\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_logs(logs)\n\u001b[1;32m    453\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m--> 454\u001b[0m     callback\u001b[39m.\u001b[39;49mon_epoch_end(epoch, logs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/callbacks.py:1476\u001b[0m, in \u001b[0;36mModelCheckpoint.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs_since_last_save \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1475\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_freq \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 1476\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_model(epoch\u001b[39m=\u001b[39;49mepoch, batch\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/callbacks.py:1541\u001b[0m, in \u001b[0;36mModelCheckpoint._save_model\u001b[0;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msave_weights(\n\u001b[1;32m   1536\u001b[0m             filepath,\n\u001b[1;32m   1537\u001b[0m             overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1538\u001b[0m             options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options,\n\u001b[1;32m   1539\u001b[0m         )\n\u001b[1;32m   1540\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1541\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49msave(\n\u001b[1;32m   1542\u001b[0m             filepath,\n\u001b[1;32m   1543\u001b[0m             overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1544\u001b[0m             options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_options,\n\u001b[1;32m   1545\u001b[0m         )\n\u001b[1;32m   1546\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1547\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/engine/training.py:2795\u001b[0m, in \u001b[0;36mModel.save\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2740\u001b[0m \u001b[39m@traceback_utils\u001b[39m\u001b[39m.\u001b[39mfilter_traceback\n\u001b[1;32m   2741\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave\u001b[39m(\n\u001b[1;32m   2742\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2749\u001b[0m     save_traces\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   2750\u001b[0m ):\n\u001b[1;32m   2752\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Saves the model to Tensorflow SavedModel or a single HDF5 file.\u001b[39;00m\n\u001b[1;32m   2753\u001b[0m \n\u001b[1;32m   2754\u001b[0m \u001b[39m    Please see `tf.keras.models.save_model` or the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2792\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[1;32m   2793\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2795\u001b[0m     save\u001b[39m.\u001b[39;49msave_model(\n\u001b[1;32m   2796\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2797\u001b[0m         filepath,\n\u001b[1;32m   2798\u001b[0m         overwrite,\n\u001b[1;32m   2799\u001b[0m         include_optimizer,\n\u001b[1;32m   2800\u001b[0m         save_format,\n\u001b[1;32m   2801\u001b[0m         signatures,\n\u001b[1;32m   2802\u001b[0m         options,\n\u001b[1;32m   2803\u001b[0m         save_traces,\n\u001b[1;32m   2804\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/saving/legacy/save.py:167\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[39mwith\u001b[39;00m serialization\u001b[39m.\u001b[39mSharedObjectSavingScope():\n\u001b[0;32m--> 167\u001b[0m         saved_model_save\u001b[39m.\u001b[39;49msave(\n\u001b[1;32m    168\u001b[0m             model,\n\u001b[1;32m    169\u001b[0m             filepath,\n\u001b[1;32m    170\u001b[0m             overwrite,\n\u001b[1;32m    171\u001b[0m             include_optimizer,\n\u001b[1;32m    172\u001b[0m             signatures,\n\u001b[1;32m    173\u001b[0m             options,\n\u001b[1;32m    174\u001b[0m             save_traces,\n\u001b[1;32m    175\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/saving/legacy/saved_model/save.py:97\u001b[0m, in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mwith\u001b[39;00m backend\u001b[39m.\u001b[39mdeprecated_internal_learning_phase_scope(\u001b[39m0\u001b[39m):\n\u001b[1;32m     96\u001b[0m     \u001b[39mwith\u001b[39;00m utils\u001b[39m.\u001b[39mkeras_option_scope(save_traces):\n\u001b[0;32m---> 97\u001b[0m         saved_nodes, node_paths \u001b[39m=\u001b[39m save_lib\u001b[39m.\u001b[39;49msave_and_return_nodes(\n\u001b[1;32m     98\u001b[0m             model, filepath, signatures, options\n\u001b[1;32m     99\u001b[0m         )\n\u001b[1;32m    101\u001b[0m     \u001b[39m# Save all metadata to a separate file in the SavedModel directory.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     metadata \u001b[39m=\u001b[39m generate_keras_metadata(saved_nodes, node_paths)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py:1267\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1263\u001b[0m saved_model \u001b[39m=\u001b[39m saved_model_pb2\u001b[39m.\u001b[39mSavedModel()\n\u001b[1;32m   1264\u001b[0m meta_graph_def \u001b[39m=\u001b[39m saved_model\u001b[39m.\u001b[39mmeta_graphs\u001b[39m.\u001b[39madd()\n\u001b[1;32m   1266\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 1267\u001b[0m     _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[1;32m   1268\u001b[0m saved_model\u001b[39m.\u001b[39msaved_model_schema_version \u001b[39m=\u001b[39m (\n\u001b[1;32m   1269\u001b[0m     constants\u001b[39m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[1;32m   1271\u001b[0m \u001b[39m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m \u001b[39m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py:1440\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m \n\u001b[1;32m   1415\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[39m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[1;32m   1437\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1439\u001b[0m \u001b[39mwith\u001b[39;00m save_context\u001b[39m.\u001b[39msave_context(options):\n\u001b[0;32m-> 1440\u001b[0m   \u001b[39mreturn\u001b[39;00m _build_meta_graph_impl(obj, signatures, options, meta_graph_def)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py:1393\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1390\u001b[0m augmented_graph_view\u001b[39m.\u001b[39mset_signature(signature_map, wrapped_functions)\n\u001b[1;32m   1392\u001b[0m \u001b[39m# Use _SaveableView to provide a frozen listing of properties and functions.\u001b[39;00m\n\u001b[0;32m-> 1393\u001b[0m saveable_view \u001b[39m=\u001b[39m _SaveableView(augmented_graph_view, options)\n\u001b[1;32m   1394\u001b[0m object_saver \u001b[39m=\u001b[39m checkpoint\u001b[39m.\u001b[39mTrackableSaver(augmented_graph_view)\n\u001b[1;32m   1395\u001b[0m asset_info, exported_graph \u001b[39m=\u001b[39m _fill_meta_graph_def(\n\u001b[1;32m   1396\u001b[0m     meta_graph_def, saveable_view, signatures, options\u001b[39m.\u001b[39mnamespace_whitelist,\n\u001b[1;32m   1397\u001b[0m     options\u001b[39m.\u001b[39mexperimental_custom_gradients)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py:266\u001b[0m, in \u001b[0;36m_SaveableView.__init__\u001b[0;34m(self, augmented_graph_view, options)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugmented_graph_view \u001b[39m=\u001b[39m augmented_graph_view\n\u001b[1;32m    262\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options \u001b[39m=\u001b[39m options\n\u001b[1;32m    264\u001b[0m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trackable_objects, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_paths, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_ids,\n\u001b[1;32m    265\u001b[0m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slot_variables, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobject_names) \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 266\u001b[0m      checkpoint_util\u001b[39m.\u001b[39;49mobjects_ids_and_slot_variables_and_paths(\n\u001b[1;32m    267\u001b[0m          \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maugmented_graph_view))\n\u001b[1;32m    269\u001b[0m untraced_functions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugmented_graph_view\u001b[39m.\u001b[39muntraced_functions\n\u001b[1;32m    270\u001b[0m \u001b[39mif\u001b[39;00m untraced_functions:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/util.py:159\u001b[0m, in \u001b[0;36mobjects_ids_and_slot_variables_and_paths\u001b[0;34m(graph_view)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjects_ids_and_slot_variables_and_paths\u001b[39m(graph_view):\n\u001b[1;32m    145\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Traverse the object graph and list all accessible objects.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[39m  Looks for `Trackable` objects which are dependencies of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39m                object -> node id, slot variables, object_names)\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m   trackable_objects, node_paths \u001b[39m=\u001b[39m graph_view\u001b[39m.\u001b[39;49mbreadth_first_traversal()\n\u001b[1;32m    160\u001b[0m   object_names \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentityDictionary()\n\u001b[1;32m    161\u001b[0m   \u001b[39mfor\u001b[39;00m obj, path \u001b[39min\u001b[39;00m node_paths\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/graph_view.py:124\u001b[0m, in \u001b[0;36mObjectGraphView.breadth_first_traversal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbreadth_first_traversal\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 124\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_breadth_first_traversal()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py:143\u001b[0m, in \u001b[0;36m_AugmentedGraphView._breadth_first_traversal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns all trackable objects in the SavedObjectGraph.\"\"\"\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39m# This method is overriden to merge all equivalent constant tensors and\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39m# Assets in the object graph.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m trackable_objects, _ \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 143\u001b[0m     \u001b[39msuper\u001b[39;49m(_AugmentedGraphView, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_breadth_first_traversal())\n\u001b[1;32m    145\u001b[0m asset_paths \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentityDictionary()\n\u001b[1;32m    146\u001b[0m constant_captures \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentityDictionary()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/graph_view.py:128\u001b[0m, in \u001b[0;36mObjectGraphView._breadth_first_traversal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_breadth_first_traversal\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    127\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Find shortest paths to all dependencies of self.root.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(ObjectGraphView, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_descendants_with_paths()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/trackable_view.py:111\u001b[0m, in \u001b[0;36mTrackableView._descendants_with_paths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m current_trackable \u001b[39m=\u001b[39m to_visit\u001b[39m.\u001b[39mpopleft()\n\u001b[1;32m    110\u001b[0m bfs_sorted\u001b[39m.\u001b[39mappend(current_trackable)\n\u001b[0;32m--> 111\u001b[0m \u001b[39mfor\u001b[39;00m name, dependency \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchildren(current_trackable)\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    112\u001b[0m   \u001b[39mif\u001b[39;00m dependency \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m node_paths:\n\u001b[1;32m    113\u001b[0m     node_paths[dependency] \u001b[39m=\u001b[39m (\n\u001b[1;32m    114\u001b[0m         node_paths[current_trackable] \u001b[39m+\u001b[39m\n\u001b[1;32m    115\u001b[0m         (base\u001b[39m.\u001b[39mTrackableReference(name, dependency),))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/graph_view.py:97\u001b[0m, in \u001b[0;36mObjectGraphView.children\u001b[0;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns all child trackables attached to obj.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[1;32m     88\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m  Dictionary of all children attached to the object with name to trackable.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m children \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> 97\u001b[0m \u001b[39mfor\u001b[39;00m name, ref \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlist_children(obj, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     98\u001b[0m   children[name] \u001b[39m=\u001b[39m ref\n\u001b[1;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m children\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py:177\u001b[0m, in \u001b[0;36m_AugmentedGraphView.list_children\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_children_cache:\n\u001b[1;32m    175\u001b[0m   children \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_children_cache[obj] \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 177\u001b[0m   \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m \u001b[39msuper\u001b[39;49m(_AugmentedGraphView, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlist_children(\n\u001b[1;32m    178\u001b[0m       obj,\n\u001b[1;32m    179\u001b[0m       save_type\u001b[39m=\u001b[39;49mbase\u001b[39m.\u001b[39;49mSaveType\u001b[39m.\u001b[39;49mSAVEDMODEL,\n\u001b[1;32m    180\u001b[0m       cache\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_serialization_cache):\n\u001b[1;32m    181\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(child, defun\u001b[39m.\u001b[39mConcreteFunction):\n\u001b[1;32m    182\u001b[0m       child \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_uncache_variable_captures(child)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/graph_view.py:75\u001b[0m, in \u001b[0;36mObjectGraphView.list_children\u001b[0;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns list of all child trackables attached to obj.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[1;32m     66\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m  List of all children attached to the object.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m children \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 75\u001b[0m \u001b[39mfor\u001b[39;00m name, ref \u001b[39min\u001b[39;00m \u001b[39msuper\u001b[39;49m(ObjectGraphView,\n\u001b[1;32m     76\u001b[0m                        \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mchildren(obj, save_type, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     77\u001b[0m   children\u001b[39m.\u001b[39mappend(base\u001b[39m.\u001b[39mTrackableReference(name, ref))\n\u001b[1;32m     79\u001b[0m \u001b[39m# GraphView objects may define children of the root object that are not\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39m# actually attached, e.g. a Checkpoint object's save_counter.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/trackable_view.py:84\u001b[0m, in \u001b[0;36mTrackableView.children\u001b[0;34m(cls, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m obj\u001b[39m.\u001b[39m_maybe_initialize_trackable()\n\u001b[1;32m     83\u001b[0m children \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> 84\u001b[0m \u001b[39mfor\u001b[39;00m name, ref \u001b[39min\u001b[39;00m obj\u001b[39m.\u001b[39;49m_trackable_children(save_type, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     85\u001b[0m   ref \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39mconvert_to_trackable(ref, parent\u001b[39m=\u001b[39mobj)\n\u001b[1;32m     86\u001b[0m   children[name] \u001b[39m=\u001b[39m ref\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/trackable/autotrackable.py:115\u001b[0m, in \u001b[0;36mAutoTrackable._trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mfor\u001b[39;00m fn \u001b[39min\u001b[39;00m functions\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    114\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fn, core_types\u001b[39m.\u001b[39mGenericFunction):\n\u001b[0;32m--> 115\u001b[0m     fn\u001b[39m.\u001b[39;49m_list_all_concrete_functions_for_serialization()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m# Additional dependencies may have been generated during function tracing\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# (e.g. captured variables). Make sure we return those too.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m children \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1160\u001b[0m, in \u001b[0;36mFunction._list_all_concrete_functions_for_serialization\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m concrete_functions \u001b[39m=\u001b[39m []\n\u001b[1;32m   1159\u001b[0m \u001b[39mfor\u001b[39;00m args, kwargs \u001b[39min\u001b[39;00m seen_signatures:\n\u001b[0;32m-> 1160\u001b[0m   concrete_functions\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_concrete_function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m   1161\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_functions\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1215\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1214\u001b[0m   \u001b[39m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1215\u001b[0m   concrete \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1216\u001b[0m   concrete\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1206\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1201\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn\u001b[39m.\u001b[39m_get_concrete_function_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m       \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1203\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1204\u001b[0m   \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m   \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m-> 1206\u001b[0m   concrete \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m   1207\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1208\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m   1209\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1210\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:192\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mvalidate_inputs_with_signature(args, kwargs)\n\u001b[1;32m    191\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 192\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[1;32m    193\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    194\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m    195\u001b[0m       concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:157\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    155\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:360\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m    358\u001b[0m   args, kwargs \u001b[39m=\u001b[39m generalized_func_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(args, kwargs)\n\u001b[1;32m    362\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:284\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m    280\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m    281\u001b[0m ]\n\u001b[1;32m    282\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m    283\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 284\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    285\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m    286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m    287\u001b[0m         args,\n\u001b[1;32m    288\u001b[0m         kwargs,\n\u001b[1;32m    289\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    290\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m    291\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m    292\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m    293\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m    294\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m    295\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m    296\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1283\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1283\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1285\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:645\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    642\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    643\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    644\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 645\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    646\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/saving/legacy/saved_model/save_impl.py:632\u001b[0m, in \u001b[0;36mlayer_call_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[39mwith\u001b[39;00m base_layer_utils\u001b[39m.\u001b[39mcall_context()\u001b[39m.\u001b[39menter(\n\u001b[1;32m    623\u001b[0m     layer,\n\u001b[1;32m    624\u001b[0m     inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m     saving\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    628\u001b[0m ):\n\u001b[1;32m    629\u001b[0m     \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    630\u001b[0m         layer\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m    631\u001b[0m     ):\n\u001b[0;32m--> 632\u001b[0m         ret \u001b[39m=\u001b[39m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    633\u001b[0m _restore_layer_losses(original_losses)\n\u001b[1;32m    634\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/saving/legacy/saved_model/utils.py:190\u001b[0m, in \u001b[0;36mmaybe_add_training_arg.<locals>.wrap_with_training_arg\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m     new_args, new_kwargs \u001b[39m=\u001b[39m call_spec\u001b[39m.\u001b[39mset_arg_value(\n\u001b[1;32m    186\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, training, args, kwargs, inputs_in_args\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    188\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_call(\u001b[39m*\u001b[39mnew_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n\u001b[0;32m--> 190\u001b[0m \u001b[39mreturn\u001b[39;00m control_flow_util\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[1;32m    191\u001b[0m     training,\n\u001b[1;32m    192\u001b[0m     \u001b[39mlambda\u001b[39;49;00m: replace_training_and_call(\u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m    193\u001b[0m     \u001b[39mlambda\u001b[39;49;00m: replace_training_and_call(\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    194\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/utils/control_flow_util.py:108\u001b[0m, in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pred, tf\u001b[39m.\u001b[39mVariable):\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcond(pred, true_fn\u001b[39m=\u001b[39mtrue_fn, false_fn\u001b[39m=\u001b[39mfalse_fn, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m--> 108\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49msmart_cond\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[1;32m    109\u001b[0m     pred, true_fn\u001b[39m=\u001b[39;49mtrue_fn, false_fn\u001b[39m=\u001b[39;49mfalse_fn, name\u001b[39m=\u001b[39;49mname\n\u001b[1;32m    110\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/framework/smart_cond.py:54\u001b[0m, in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m true_fn()\n\u001b[1;32m     53\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m false_fn()\n\u001b[1;32m     55\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m   \u001b[39mreturn\u001b[39;00m control_flow_ops\u001b[39m.\u001b[39mcond(pred, true_fn\u001b[39m=\u001b[39mtrue_fn, false_fn\u001b[39m=\u001b[39mfalse_fn,\n\u001b[1;32m     57\u001b[0m                                name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/saving/legacy/saved_model/utils.py:193\u001b[0m, in \u001b[0;36mmaybe_add_training_arg.<locals>.wrap_with_training_arg.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m     new_args, new_kwargs \u001b[39m=\u001b[39m call_spec\u001b[39m.\u001b[39mset_arg_value(\n\u001b[1;32m    186\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, training, args, kwargs, inputs_in_args\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    188\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_call(\u001b[39m*\u001b[39mnew_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n\u001b[1;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m control_flow_util\u001b[39m.\u001b[39msmart_cond(\n\u001b[1;32m    191\u001b[0m     training,\n\u001b[1;32m    192\u001b[0m     \u001b[39mlambda\u001b[39;00m: replace_training_and_call(\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m--> 193\u001b[0m     \u001b[39mlambda\u001b[39;00m: replace_training_and_call(\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    194\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/saving/legacy/saved_model/utils.py:188\u001b[0m, in \u001b[0;36mmaybe_add_training_arg.<locals>.wrap_with_training_arg.<locals>.replace_training_and_call\u001b[0;34m(training)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreplace_training_and_call\u001b[39m(training):\n\u001b[1;32m    185\u001b[0m     new_args, new_kwargs \u001b[39m=\u001b[39m call_spec\u001b[39m.\u001b[39mset_arg_value(\n\u001b[1;32m    186\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, training, args, kwargs, inputs_in_args\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     )\n\u001b[0;32m--> 188\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_call(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/saving/legacy/saved_model/save_impl.py:698\u001b[0m, in \u001b[0;36m_wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_and_return_conditional_losses\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    697\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns layer (call_output, conditional losses) tuple.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 698\u001b[0m     call_output \u001b[39m=\u001b[39m layer_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    699\u001b[0m     \u001b[39mif\u001b[39;00m version_utils\u001b[39m.\u001b[39mis_v1_layer_or_model(layer):\n\u001b[1;32m    700\u001b[0m         conditional_losses \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mget_losses_for(\n\u001b[1;32m    701\u001b[0m             _filtered_inputs([args, kwargs])\n\u001b[1;32m    702\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/engine/sequential.py:413\u001b[0m, in \u001b[0;36mSequential.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[1;32m    412\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_graph_network(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs)\n\u001b[0;32m--> 413\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcall(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[1;32m    415\u001b[0m outputs \u001b[39m=\u001b[39m inputs  \u001b[39m# handle the corner case where self.layers is empty\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m    417\u001b[0m     \u001b[39m# During each iteration, `inputs` are the inputs to `layer`, and\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     \u001b[39m# `outputs` are the outputs of `layer` applied to `inputs`. At the\u001b[39;00m\n\u001b[1;32m    419\u001b[0m     \u001b[39m# end of each iteration `inputs` is set to `outputs` to prepare for\u001b[39;00m\n\u001b[1;32m    420\u001b[0m     \u001b[39m# the next layer.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/engine/functional.py:511\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[1;32m    493\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    494\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \n\u001b[1;32m    496\u001b[0m \u001b[39m    In this case `call` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/engine/functional.py:668\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    667\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[0;32m--> 668\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mlayer(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    670\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    671\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[1;32m    672\u001b[0m     node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[1;32m    673\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/layers/rnn/bidirectional.py:278\u001b[0m, in \u001b[0;36mBidirectional.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m     inputs \u001b[39m=\u001b[39m inputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    280\u001b[0m \u001b[39m# Applies the same workaround as in `RNN.__call__`\u001b[39;00m\n\u001b[1;32m    281\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/engine/base_layer.py:1132\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1129\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1131\u001b[0m ):\n\u001b[0;32m-> 1132\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1135\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/layers/rnn/bidirectional.py:405\u001b[0m, in \u001b[0;36mBidirectional.call\u001b[0;34m(self, inputs, training, mask, initial_state, constants)\u001b[0m\n\u001b[1;32m    402\u001b[0m         forward_inputs, backward_inputs \u001b[39m=\u001b[39m inputs, inputs\n\u001b[1;32m    403\u001b[0m         forward_state, backward_state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 405\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_layer(\n\u001b[1;32m    406\u001b[0m         forward_inputs, initial_state\u001b[39m=\u001b[39;49mforward_state, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    407\u001b[0m     )\n\u001b[1;32m    408\u001b[0m     y_rev \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward_layer(\n\u001b[1;32m    409\u001b[0m         backward_inputs, initial_state\u001b[39m=\u001b[39mbackward_state, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/layers/rnn/base_rnn.py:556\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m rnn_utils\u001b[39m.\u001b[39mstandardize_args(\n\u001b[1;32m    552\u001b[0m     inputs, initial_state, constants, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants\n\u001b[1;32m    553\u001b[0m )\n\u001b[1;32m    555\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 556\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    558\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[1;32m    562\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/engine/base_layer.py:1132\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1129\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1131\u001b[0m ):\n\u001b[0;32m-> 1132\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1135\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/layers/rnn/lstm.py:751\u001b[0m, in \u001b[0;36mLSTM.call\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    737\u001b[0m                 (\n\u001b[1;32m    738\u001b[0m                     last_output,\n\u001b[1;32m    739\u001b[0m                     outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     runtime,\n\u001b[1;32m    743\u001b[0m                 ) \u001b[39m=\u001b[39m standard_lstm(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnormal_lstm_kwargs)\n\u001b[1;32m    744\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    745\u001b[0m             (\n\u001b[1;32m    746\u001b[0m                 last_output,\n\u001b[1;32m    747\u001b[0m                 outputs,\n\u001b[1;32m    748\u001b[0m                 new_h,\n\u001b[1;32m    749\u001b[0m                 new_c,\n\u001b[1;32m    750\u001b[0m                 runtime,\n\u001b[0;32m--> 751\u001b[0m             ) \u001b[39m=\u001b[39m lstm_with_backend_selection(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnormal_lstm_kwargs)\n\u001b[1;32m    753\u001b[0m     states \u001b[39m=\u001b[39m [new_h, new_c]\n\u001b[1;32m    755\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateful:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/layers/rnn/lstm.py:1353\u001b[0m, in \u001b[0;36mlstm_with_backend_selection\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     defun_gpu_lstm \u001b[39m=\u001b[39m gru_lstm_utils\u001b[39m.\u001b[39mgenerate_defun_backend(\n\u001b[1;32m   1345\u001b[0m         api_name,\n\u001b[1;32m   1346\u001b[0m         gru_lstm_utils\u001b[39m.\u001b[39mGPU_DEVICE_NAME,\n\u001b[1;32m   1347\u001b[0m         gpu_lstm_with_fallback,\n\u001b[1;32m   1348\u001b[0m         supportive_attribute,\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1351\u001b[0m     \u001b[39m# Call the normal LSTM impl and register the cuDNN impl function. The\u001b[39;00m\n\u001b[1;32m   1352\u001b[0m     \u001b[39m# grappler will kick in during session execution to optimize the graph.\u001b[39;00m\n\u001b[0;32m-> 1353\u001b[0m     last_output, outputs, new_h, new_c, runtime \u001b[39m=\u001b[39m defun_standard_lstm(\n\u001b[1;32m   1354\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m   1355\u001b[0m     )\n\u001b[1;32m   1356\u001b[0m     gru_lstm_utils\u001b[39m.\u001b[39mfunction_register(defun_gpu_lstm, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m   1358\u001b[0m \u001b[39mreturn\u001b[39;00m last_output, outputs, new_h, new_c, runtime\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:133\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m--> 133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:360\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m    358\u001b[0m   args, kwargs \u001b[39m=\u001b[39m generalized_func_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(args, kwargs)\n\u001b[1;32m    362\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:284\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m    280\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m    281\u001b[0m ]\n\u001b[1;32m    282\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m    283\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 284\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    285\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m    286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m    287\u001b[0m         args,\n\u001b[1;32m    288\u001b[0m         kwargs,\n\u001b[1;32m    289\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    290\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m    291\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m    292\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m    293\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m    294\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m    295\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m    296\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1283\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1283\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1285\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/layers/rnn/lstm.py:983\u001b[0m, in \u001b[0;36mstandard_lstm\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[1;32m    980\u001b[0m     h \u001b[39m=\u001b[39m o \u001b[39m*\u001b[39m tf\u001b[39m.\u001b[39mtanh(c)\n\u001b[1;32m    981\u001b[0m     \u001b[39mreturn\u001b[39;00m h, [h, c]\n\u001b[0;32m--> 983\u001b[0m last_output, outputs, new_states \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39;49mrnn(\n\u001b[1;32m    984\u001b[0m     step,\n\u001b[1;32m    985\u001b[0m     inputs,\n\u001b[1;32m    986\u001b[0m     [init_h, init_c],\n\u001b[1;32m    987\u001b[0m     constants\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    988\u001b[0m     unroll\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    989\u001b[0m     time_major\u001b[39m=\u001b[39;49mtime_major,\n\u001b[1;32m    990\u001b[0m     mask\u001b[39m=\u001b[39;49mmask,\n\u001b[1;32m    991\u001b[0m     go_backwards\u001b[39m=\u001b[39;49mgo_backwards,\n\u001b[1;32m    992\u001b[0m     input_length\u001b[39m=\u001b[39;49m(\n\u001b[1;32m    993\u001b[0m         sequence_lengths \u001b[39mif\u001b[39;49;00m sequence_lengths \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m timesteps\n\u001b[1;32m    994\u001b[0m     ),\n\u001b[1;32m    995\u001b[0m     zero_output_for_mask\u001b[39m=\u001b[39;49mzero_output_for_mask,\n\u001b[1;32m    996\u001b[0m     return_all_outputs\u001b[39m=\u001b[39;49mreturn_sequences,\n\u001b[1;32m    997\u001b[0m )\n\u001b[1;32m    998\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    999\u001b[0m     last_output,\n\u001b[1;32m   1000\u001b[0m     outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     gru_lstm_utils\u001b[39m.\u001b[39mruntime(gru_lstm_utils\u001b[39m.\u001b[39mRUNTIME_CPU),\n\u001b[1;32m   1004\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/backend.py:5142\u001b[0m, in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[0m\n\u001b[1;32m   5137\u001b[0m         new_states \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   5138\u001b[0m             initial_states, flat_new_state\n\u001b[1;32m   5139\u001b[0m         )\n\u001b[1;32m   5140\u001b[0m         \u001b[39mreturn\u001b[39;00m (time \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, output_ta_t) \u001b[39m+\u001b[39m \u001b[39mtuple\u001b[39m(new_states)\n\u001b[0;32m-> 5142\u001b[0m     final_outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[1;32m   5143\u001b[0m         body\u001b[39m=\u001b[39;49m_step,\n\u001b[1;32m   5144\u001b[0m         loop_vars\u001b[39m=\u001b[39;49m(time, output_ta) \u001b[39m+\u001b[39;49m states,\n\u001b[1;32m   5145\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mwhile_loop_kwargs,\n\u001b[1;32m   5146\u001b[0m     )\n\u001b[1;32m   5147\u001b[0m     new_states \u001b[39m=\u001b[39m final_outputs[\u001b[39m2\u001b[39m:]\n\u001b[1;32m   5149\u001b[0m output_ta \u001b[39m=\u001b[39m final_outputs[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/ops/control_flow_ops.py:2716\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2713\u001b[0m executing_eagerly \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mexecuting_eagerly()\n\u001b[1;32m   2714\u001b[0m \u001b[39mif\u001b[39;00m (util\u001b[39m.\u001b[39mEnableControlFlowV2(ops\u001b[39m.\u001b[39mget_default_graph()) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   2715\u001b[0m     \u001b[39mnot\u001b[39;00m executing_eagerly):\n\u001b[0;32m-> 2716\u001b[0m   \u001b[39mreturn\u001b[39;00m while_v2\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[1;32m   2717\u001b[0m       cond,\n\u001b[1;32m   2718\u001b[0m       body,\n\u001b[1;32m   2719\u001b[0m       loop_vars,\n\u001b[1;32m   2720\u001b[0m       shape_invariants\u001b[39m=\u001b[39;49mshape_invariants,\n\u001b[1;32m   2721\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m   2722\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[1;32m   2723\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2724\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49mreturn_same_structure,\n\u001b[1;32m   2725\u001b[0m       back_prop\u001b[39m=\u001b[39;49mback_prop)\n\u001b[1;32m   2727\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mwhile\u001b[39m\u001b[39m\"\u001b[39m, loop_vars):\n\u001b[1;32m   2728\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m loop_vars:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/ops/while_v2.py:222\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure, back_prop)\u001b[0m\n\u001b[1;32m    218\u001b[0m   \u001b[39m# TODO(srbs): Update lowering code to create _Enter nodes with\u001b[39;00m\n\u001b[1;32m    219\u001b[0m   \u001b[39m# is_constant=True for inputs that are directly passed to outputs.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m   \u001b[39mreturn\u001b[39;00m [loop_counter \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, maximum_iterations_arg] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(outputs)\n\u001b[0;32m--> 222\u001b[0m body_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    223\u001b[0m     body_name,\n\u001b[1;32m    224\u001b[0m     wrapped_body,\n\u001b[1;32m    225\u001b[0m     [],  \u001b[39m# We provide signature instead of args.\u001b[39;49;00m\n\u001b[1;32m    226\u001b[0m     {},\n\u001b[1;32m    227\u001b[0m     signature\u001b[39m=\u001b[39;49mfunc_graph_signature,\n\u001b[1;32m    228\u001b[0m     func_graph\u001b[39m=\u001b[39;49mutil\u001b[39m.\u001b[39;49mWhileBodyFuncGraph(\n\u001b[1;32m    229\u001b[0m         body_name, collections\u001b[39m=\u001b[39;49mops\u001b[39m.\u001b[39;49mget_default_graph()\u001b[39m.\u001b[39;49m_collections),  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    230\u001b[0m     add_control_dependencies\u001b[39m=\u001b[39;49madd_control_dependencies,\n\u001b[1;32m    231\u001b[0m     acd_record_initial_resource_uses\u001b[39m=\u001b[39;49mstateful_parallelism)\n\u001b[1;32m    232\u001b[0m \u001b[39m# Add external captures of body to the list of loop vars.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39m# Note that external tensors will be treated as loop invariants, i.e.,\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39m# the value of that tensor in each iteration is the same as it was at the\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m# beginning of the loop execution.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m deferred_external_captures \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mflatten(\n\u001b[1;32m    237\u001b[0m     [c() \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m body_graph\u001b[39m.\u001b[39mdeferred_external_captures],\n\u001b[1;32m    238\u001b[0m     expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1283\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1283\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1285\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/ops/while_v2.py:200\u001b[0m, in \u001b[0;36mwhile_loop.<locals>.wrapped_body\u001b[0;34m(loop_counter, maximum_iterations_arg, *args)\u001b[0m\n\u001b[1;32m    193\u001b[0m   ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39mcapture(t)\n\u001b[1;32m    195\u001b[0m \u001b[39m# Convert the flow variables in `args` to TensorArrays. `args` should\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# already have the same structure as `orig_loop_vars` but currently there\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m# is no nest.zip so we call `_pack_sequence_as` which flattens `args`,\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# converts flows in `args` to TensorArrays and packs it into the\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# structure of `loop_vars_signature`.\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m outputs \u001b[39m=\u001b[39m body(\n\u001b[1;32m    201\u001b[0m     \u001b[39m*\u001b[39;49m_pack_sequence_as(loop_vars_signature, flat_orig_loop_vars, args))\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nest\u001b[39m.\u001b[39mis_nested(outputs):\n\u001b[1;32m    203\u001b[0m   outputs \u001b[39m=\u001b[39m [outputs]\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/backend.py:5119\u001b[0m, in \u001b[0;36mrnn.<locals>._step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m   5108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_step\u001b[39m(time, output_ta_t, \u001b[39m*\u001b[39mstates):\n\u001b[1;32m   5109\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"RNN step function.\u001b[39;00m\n\u001b[1;32m   5110\u001b[0m \n\u001b[1;32m   5111\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5117\u001b[0m \u001b[39m        Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\u001b[39;00m\n\u001b[1;32m   5118\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5119\u001b[0m     current_input \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(ta\u001b[39m.\u001b[39;49mread(time) \u001b[39mfor\u001b[39;49;00m ta \u001b[39min\u001b[39;49;00m input_ta)\n\u001b[1;32m   5120\u001b[0m     current_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(inputs, current_input)\n\u001b[1;32m   5121\u001b[0m     output, new_states \u001b[39m=\u001b[39m step_function(\n\u001b[1;32m   5122\u001b[0m         current_input, \u001b[39mtuple\u001b[39m(states) \u001b[39m+\u001b[39m \u001b[39mtuple\u001b[39m(constants)\n\u001b[1;32m   5123\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/backend.py:5119\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_step\u001b[39m(time, output_ta_t, \u001b[39m*\u001b[39mstates):\n\u001b[1;32m   5109\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"RNN step function.\u001b[39;00m\n\u001b[1;32m   5110\u001b[0m \n\u001b[1;32m   5111\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5117\u001b[0m \u001b[39m        Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\u001b[39;00m\n\u001b[1;32m   5118\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5119\u001b[0m     current_input \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ta\u001b[39m.\u001b[39;49mread(time) \u001b[39mfor\u001b[39;00m ta \u001b[39min\u001b[39;00m input_ta)\n\u001b[1;32m   5120\u001b[0m     current_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(inputs, current_input)\n\u001b[1;32m   5121\u001b[0m     output, new_states \u001b[39m=\u001b[39m step_function(\n\u001b[1;32m   5122\u001b[0m         current_input, \u001b[39mtuple\u001b[39m(states) \u001b[39m+\u001b[39m \u001b[39mtuple\u001b[39m(constants)\n\u001b[1;32m   5123\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/ops/tensor_array_ops.py:1155\u001b[0m, in \u001b[0;36mTensorArray.read\u001b[0;34m(self, index, name)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, index, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1146\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Read the value at location `index` in the TensorArray.\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \n\u001b[1;32m   1148\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[39m    The tensor at index `index`.\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1155\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_implementation\u001b[39m.\u001b[39;49mread(index, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/ops/tensor_array_ops.py:529\u001b[0m, in \u001b[0;36m_GraphTensorArrayV2.read\u001b[0;34m(self, index, name)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"See TensorArray.\"\"\"\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mTensorArrayV2Read\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flow, index]):\n\u001b[0;32m--> 529\u001b[0m   value \u001b[39m=\u001b[39m list_ops\u001b[39m.\u001b[39;49mtensor_list_get_item(\n\u001b[1;32m    530\u001b[0m       input_handle\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flow,\n\u001b[1;32m    531\u001b[0m       index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    532\u001b[0m       element_dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype,\n\u001b[1;32m    533\u001b[0m       element_shape\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49melement_shape,\n\u001b[1;32m    534\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m    535\u001b[0m   \u001b[39mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/ops/list_ops.py:105\u001b[0m, in \u001b[0;36mtensor_list_get_item\u001b[0;34m(input_handle, index, element_dtype, element_shape, name)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtensor_list_get_item\u001b[39m(input_handle, index, element_dtype, element_shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    104\u001b[0m                          name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 105\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_list_ops\u001b[39m.\u001b[39;49mtensor_list_get_item(\n\u001b[1;32m    106\u001b[0m       input_handle\u001b[39m=\u001b[39;49minput_handle,\n\u001b[1;32m    107\u001b[0m       index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    108\u001b[0m       element_shape\u001b[39m=\u001b[39;49m_build_element_shape(element_shape),\n\u001b[1;32m    109\u001b[0m       element_dtype\u001b[39m=\u001b[39;49melement_dtype,\n\u001b[1;32m    110\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/ops/gen_list_ops.py:562\u001b[0m, in \u001b[0;36mtensor_list_get_item\u001b[0;34m(input_handle, index, element_shape, element_dtype, name)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m    561\u001b[0m element_dtype \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_type(element_dtype, \u001b[39m\"\u001b[39m\u001b[39melement_dtype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 562\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[1;32m    563\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mTensorListGetItem\u001b[39;49m\u001b[39m\"\u001b[39;49m, input_handle\u001b[39m=\u001b[39;49minput_handle, index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    564\u001b[0m                            element_shape\u001b[39m=\u001b[39;49melement_shape,\n\u001b[1;32m    565\u001b[0m                            element_dtype\u001b[39m=\u001b[39;49melement_dtype, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m    566\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m    567\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py:795\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    790\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    791\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[1;32m    792\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    793\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    794\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 795\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    796\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m    797\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m    799\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:749\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    747\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[1;32m    748\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[0;32m--> 749\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    750\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    751\u001b[0m     compute_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:3798\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3795\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   3796\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   3797\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 3798\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[1;32m   3799\u001b[0m       node_def,\n\u001b[1;32m   3800\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   3801\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m   3802\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[1;32m   3803\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[1;32m   3804\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m   3805\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[1;32m   3806\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m   3807\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[1;32m   3808\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:2106\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2103\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[1;32m   2105\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[0;32m-> 2106\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m   2107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_c_op(c_op\u001b[39m=\u001b[39mc_op, g\u001b[39m=\u001b[39mg)\n\u001b[1;32m   2109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1964\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1960\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[1;32m   1961\u001b[0m                                          serialized)\n\u001b[1;32m   1963\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1964\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[1;32m   1965\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1966\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=4096\n",
    "tuner.search(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "best_hp_random = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(best_hp_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "input_dim = 100  # Word2Vec vector size\n",
    "output_dim = 7   # Number of sentiment labels\n",
    "hidden_units = 32  # LSTM hidden units\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=input_dim+1, output_dim=input_dim, input_length=input_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "model.summary()\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=4096, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
