{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# LSTM-GloVe Model for Sentiment Analysis in text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "En este notebook se describe el proceso de carga, preprocesamiento, embedding, construcción y entrenamiento de un modelo que emplea LSTM y GloVe\n",
    "para el set de datos de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Carga de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A continuación se cargará el dataset unificado que se construyó en etapas anteriores (Ver `data_join.ipynb` y `NLP_tasks.ipynb`) que cuenta con cas 66000 registros de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T00:58:40.087569Z",
     "start_time": "2023-05-01T00:58:37.798720Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  @tiffanylue i know  i was listenin to bad habi...\n",
       "1      0  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2      0                Funeral ceremony...gloomy friday...\n",
       "3      1               wants to hang out with friends SOON!\n",
       "4      6  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../../data/cleaned/out.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T00:58:53.413010Z",
     "start_time": "2023-05-01T00:58:53.381796Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65989, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Emociones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Se realizará el método de one_hot_encoding para nuestra varible de salida del modelo: Las 7 emociones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T00:58:57.695393Z",
     "start_time": "2023-05-01T00:58:57.633498Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 6 4 5 2 3]\n"
     ]
    }
   ],
   "source": [
    "#Emociones\n",
    "emotions = data['label'].unique()\n",
    "print(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T00:58:59.181639Z",
     "start_time": "2023-05-01T00:58:59.063532Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65988</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6\n",
       "0      1  0  0  0  0  0  0\n",
       "1      1  0  0  0  0  0  0\n",
       "2      1  0  0  0  0  0  0\n",
       "3      0  1  0  0  0  0  0\n",
       "4      0  0  0  0  0  0  1\n",
       "...   .. .. .. .. .. .. ..\n",
       "65984  0  0  0  0  0  0  1\n",
       "65985  0  0  0  0  0  0  1\n",
       "65986  0  0  0  0  0  1  0\n",
       "65987  0  0  0  0  0  0  1\n",
       "65988  0  1  0  0  0  0  0\n",
       "\n",
       "[65989 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(data.label)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Es necesario remover de nuestros datos información irrelevante como etiquetas, puntución, números y caracteres especiales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T00:59:03.264094Z",
     "start_time": "2023-05-01T00:59:03.247716Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =['"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T00:59:06.689496Z",
     "start_time": "2023-05-01T00:59:06.645635Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'@[^> ]+')\n",
    "\n",
    "def remove_at_sign(sentence: str):\n",
    "    '''\n",
    "    Replaces '@' from and input string for an empty space\n",
    "    :param sentence: String that contains @\n",
    "    :return: sentence without @\n",
    "    '''\n",
    "\n",
    "    return TAG_RE.sub('', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T00:59:08.978903Z",
     "start_time": "2023-05-01T00:59:08.954464Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' i know  i was listenin to bad habit earlier and i started freakin at his part =['"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_at_sign(data['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T00:59:19.178655Z",
     "start_time": "2023-05-01T00:59:11.277560Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yonosoysantiago/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T00:59:19.191669Z",
     "start_time": "2023-05-01T00:59:19.178655Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess_text(sentence: str):\n",
    "    '''\n",
    "    Cleans up a sentence leaving only 2 or more non-stopsentences composed of upper and lowercase\n",
    "    :param sentence: String to be cleaned\n",
    "    :return: sentence without numbers, special chars and long stopsentences\n",
    "    '''\n",
    "\n",
    "    cleaned_sentence = sentence.lower()\n",
    "    cleaned_sentence = remove_at_sign(cleaned_sentence)\n",
    "    cleaned_sentence = re.sub('[^a-zA-Z]', ' ', cleaned_sentence)\n",
    "    cleaned_sentence = re.sub('\\s+[a-zA-Z]\\s', ' ', cleaned_sentence)\n",
    "    cleaned_sentence = re.sub('\\s+', ' ', cleaned_sentence)\n",
    "\n",
    "    #Removal of stopsentences\n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s')\n",
    "    cleaned_sentence = pattern.sub('', cleaned_sentence)\n",
    "\n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T00:59:19.300991Z",
     "start_time": "2023-05-01T00:59:19.196670Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' know listenin bad habit earlier started freakin part '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(data['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T00:59:55.875793Z",
     "start_time": "2023-05-01T00:59:19.229466Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         know listenin bad habit earlier started freak...\n",
       "1                   layin bed headache ughhhh waitin call \n",
       "2                          funeral ceremony gloomy friday \n",
       "3                                 wants hang friends soon \n",
       "4                  want trade someone houston tickets one \n",
       "                               ...                        \n",
       "65984                                                     \n",
       "65985                       got uh joey women adam apples \n",
       "65986                                  guys messing right \n",
       "65987                                                yeah \n",
       "65988                           good one second like whoa \n",
       "Name: text, Length: 65989, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import  deepcopy\n",
    "\n",
    "cleaned_data = deepcopy(data)\n",
    "cleaned_data['text'] = cleaned_data['text'].apply(preprocess_text)\n",
    "cleaned_data['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Para el proceso de embedding se usarán los datos de un modelo de embedding como lo es GloVe.\n",
    "La información dicho modelo será cargada dentro de `words`. Cada uno de los tokens de GloVe que\n",
    "se usará tiene una dimensión de 50. En caso de que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:00:05.684493Z",
     "start_time": "2023-05-01T00:59:55.881789Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "words = {}\n",
    "\n",
    "def add_to_dict(dictionary, filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split(' ')\n",
    "\n",
    "            try:\n",
    "                dictionary[line[0]] = np.array(line[1:], dtype=float)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "add_to_dict(words, './GloVe/glove.6B/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:00:07.113715Z",
     "start_time": "2023-05-01T01:00:05.690516Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Tokenización y Lematización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Una vez cargada la información de los tokens de GloVe se procede a tokenizar y lematizar cada\n",
    "una de las oraciones en nuestro set de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:00:07.296718Z",
     "start_time": "2023-05-01T01:00:07.075667Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/yonosoysantiago/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/yonosoysantiago/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Ejemplo de cómo se debería de tokenizar y lematizar una oración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:00:09.441765Z",
     "start_time": "2023-05-01T01:00:07.267716Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['know', 'listenin', 'bad', 'habit', 'earlier', 'started', 'freakin', 'part']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sample = preprocess_text(cleaned_data['text'][0])\n",
    "token_sample = tokenizer.tokenize(sample)\n",
    "lemma_sample = [lemmatizer.lemmatize(token) for token in token_sample]\n",
    "lemma_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A continuación se define una función para la tokenización y lematización. Adicionalmente, el token final que se entrega únicamente contiene palabras definidas en `words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:00:09.516767Z",
     "start_time": "2023-05-01T01:00:09.446766Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentence_to_token_list(sentence: str):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    useful_tokens = [token for token in lemmatized_tokens if token in words]\n",
    "\n",
    "    return  useful_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:00:09.531766Z",
     "start_time": "2023-05-01T01:00:09.461765Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['know', 'bad', 'habit', 'earlier', 'started', 'freakin', 'part']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_to_token_list(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Con el token anterior, el cual sabemos se puede representar por medio de uno de los tokens almacenados en `words`, entonces pasamos a la representación de estos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:00:09.532765Z",
     "start_time": "2023-05-01T01:00:09.477767Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentence_to_words_vectors(sentence: str, word_dict=words):\n",
    "    processed_tokens = sentence_to_token_list(sentence)\n",
    "\n",
    "    vectors = []\n",
    "    for token in processed_tokens:\n",
    "        if token in word_dict:\n",
    "            token_vector = word_dict[token]\n",
    "            vectors.append(token_vector)\n",
    "\n",
    "    return np.array(vectors, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:00:09.532765Z",
     "start_time": "2023-05-01T01:00:09.494768Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_to_words_vectors(sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:00:09.545765Z",
     "start_time": "2023-05-01T01:00:09.515769Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28328  ,  0.12887  ,  0.29861  , -0.23238  ,  0.88263  ,\n",
       "        -0.30814  , -0.61148  ,  0.37254  , -0.40449  ,  0.17351  ,\n",
       "        -0.13958  ,  0.67868  , -0.55673  , -0.13453  ,  1.1441   ,\n",
       "         0.53457  ,  0.59148  ,  0.19083  ,  0.25406  , -0.71581  ,\n",
       "        -0.87951  ,  0.72879  ,  0.67054  ,  0.62866  ,  1.0034   ,\n",
       "        -2.2327   , -1.194    , -0.06245  ,  0.93933  , -1.1132   ,\n",
       "         2.926    ,  0.59809  , -0.51255  , -0.49886  , -0.016524 ,\n",
       "        -0.20697  , -0.059229 , -0.0072689,  0.53314  , -0.14621  ,\n",
       "        -0.21417  ,  0.24102  ,  0.21648  ,  0.73351  ,  0.43582  ,\n",
       "         0.045278 , -0.25489  ,  0.15273  , -0.13088  ,  0.89397  ],\n",
       "       [-0.17981  , -0.40407  , -0.1653   , -0.60687  , -0.39656  ,\n",
       "         0.12688  , -0.053049 ,  0.38024  , -0.51008  ,  0.46593  ,\n",
       "        -0.30818  ,  0.79362  , -0.85766  , -0.25143  ,  1.0448   ,\n",
       "         0.18628  ,  0.13688  ,  0.092588 , -0.2236   , -0.13604  ,\n",
       "        -0.19482  ,  0.057702 ,  0.56133  ,  0.24823  ,  0.627    ,\n",
       "        -1.8437   , -1.2573   ,  0.64482  ,  1.2787   , -0.29522  ,\n",
       "         3.0493   ,  0.62079  ,  0.90369  , -0.030099 , -0.13091  ,\n",
       "         0.30525  , -0.070138 , -0.12912  ,  0.72277  , -0.79774  ,\n",
       "        -0.70277  ,  0.038009 ,  0.27192  ,  0.35679  ,  0.26493  ,\n",
       "         0.13037  , -0.01369  ,  0.33713  ,  0.99956  ,  0.72031  ],\n",
       "       [-0.031058 , -0.24609  , -0.9077   , -1.0229   ,  0.19356  ,\n",
       "         0.53121  , -0.21515  , -0.40683  ,  0.59225  ,  1.0359   ,\n",
       "        -0.18254  ,  0.36191  ,  0.18725  , -0.0078135,  0.62996  ,\n",
       "        -0.46528  , -0.44288  ,  0.12539  , -0.0065608, -0.4708   ,\n",
       "        -0.42531  , -0.26501  ,  0.38555  ,  0.34596  ,  0.35707  ,\n",
       "        -1.2948   ,  0.42021  ,  0.45468  ,  0.91855  ,  0.14189  ,\n",
       "         1.582    ,  0.5803   ,  0.088518 , -0.033661 , -0.66021  ,\n",
       "         0.23344  , -0.70859  ,  0.52198  , -0.21834  , -0.24428  ,\n",
       "        -0.21386  , -0.27636  , -0.61687  ,  1.6641   ,  1.1188   ,\n",
       "        -0.23147  ,  0.19004  , -0.60125  ,  0.11713  , -0.25198  ],\n",
       "       [ 0.53772  , -0.17572  ,  0.16704  ,  0.2617   ,  0.0095107,\n",
       "         0.17802  , -0.8192   ,  0.023313 , -0.67016  , -0.18026  ,\n",
       "        -0.15323  , -0.70254  , -0.66864  , -0.28519  ,  0.99582  ,\n",
       "         0.11573  , -0.94466  , -0.87298  , -0.77195  ,  0.081174 ,\n",
       "         0.46313  ,  0.30321  ,  0.34776  , -0.97389  , -0.011876 ,\n",
       "        -1.5462   ,  0.23966  ,  0.18437  , -0.65125  ,  0.46257  ,\n",
       "         3.2985   , -0.31677  , -0.067658 ,  0.0084145,  0.22632  ,\n",
       "        -0.55538  ,  0.49637  ,  0.098167 , -0.32241  , -0.057772 ,\n",
       "        -0.39908  ,  0.42339  ,  0.07051  , -0.49125  ,  0.20524  ,\n",
       "        -0.068185 , -0.65967  ,  0.71609  , -0.017516 , -0.54233  ],\n",
       "       [-0.20492  , -0.47264  , -0.24182  , -0.42806  , -0.58667  ,\n",
       "        -0.29953  , -1.5043   ,  0.22041  , -0.32192  , -0.011014 ,\n",
       "         0.24347  , -0.13998  , -1.0299   , -0.076541 ,  0.57273  ,\n",
       "        -0.17379  , -0.29957  ,  0.25672  , -0.77973  , -0.053743 ,\n",
       "         0.89019  ,  0.36763  ,  0.40332  ,  0.20212  ,  0.40951  ,\n",
       "        -1.1495   ,  0.18819  , -0.27845  ,  0.22702  , -0.42631  ,\n",
       "         3.175    ,  0.32766  , -0.275    , -0.25166  , -0.21405  ,\n",
       "         0.2567   , -0.09849  ,  0.5659   ,  0.31893  ,  0.26182  ,\n",
       "        -0.44939  , -0.38002  , -0.54841  , -0.29008  ,  0.20738  ,\n",
       "        -0.060745 ,  0.26459  , -0.58691  , -0.31341  , -0.20058  ],\n",
       "       [-0.081298 , -0.18447  , -0.20424  , -1.0914   ,  0.55381  ,\n",
       "        -0.91321  , -0.15558  , -0.13129  , -0.14143  ,  1.0235   ,\n",
       "        -0.33015  ,  0.81114  , -0.17682  ,  0.40954  , -0.16874  ,\n",
       "         0.17236  ,  0.42768  , -0.042834 , -0.066574 ,  0.29009  ,\n",
       "        -1.0208   ,  0.073951 , -0.053494 ,  0.067791 ,  0.24571  ,\n",
       "         0.29656  , -1.3656   ,  0.43038  ,  0.8005   , -0.41209  ,\n",
       "        -0.51373  ,  1.1757   ,  0.077595 ,  1.1339   ,  0.35349  ,\n",
       "        -0.14229  ,  0.85759  , -0.905    ,  0.18951  ,  0.19021  ,\n",
       "        -0.56274  , -0.063354 , -1.0776   ,  0.6256   , -0.075322 ,\n",
       "         0.12923  , -0.34188  , -0.027863 ,  0.64354  ,  0.59983  ],\n",
       "       [ 0.70504  ,  0.18255  , -0.75188  ,  0.0039397, -0.053423 ,\n",
       "         0.29625  , -0.42377  , -0.013111 ,  0.16573  , -0.43932  ,\n",
       "         0.07506  , -0.16262  , -0.26635  , -0.40453  , -0.098246 ,\n",
       "         0.14215  ,  0.34546  ,  0.3634   , -0.40502  ,  0.3591   ,\n",
       "         0.37462  , -0.33984  , -0.24689  ,  0.33546  , -0.36193  ,\n",
       "        -1.7587   , -0.72343  ,  0.14269  , -0.099759 , -0.16071  ,\n",
       "         3.6203   , -0.25283  , -0.24719  , -0.53168  , -0.050993 ,\n",
       "         0.017225 , -0.12073  , -0.021644 , -0.36179  , -0.086212 ,\n",
       "        -0.32108  , -0.16623  , -0.2044   , -0.46124  , -0.85036  ,\n",
       "         0.16189  , -0.14281  , -0.13137  , -0.41208  , -0.092147 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_to_words_vectors(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:07:08.842774Z",
     "start_time": "2023-05-01T01:06:58.574974Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [[0.28328, 0.12887, 0.29861, -0.23238, 0.88263...\n",
       "1        [[0.062774, 0.25423, 0.54447, -0.49013, -0.488...\n",
       "2        [[0.89902, 1.5889, -0.34232, -0.40286, 0.97148...\n",
       "3        [[0.13627, -0.054478, 0.3703, -0.41574, 0.6056...\n",
       "4        [[0.13627, -0.054478, 0.3703, -0.41574, 0.6056...\n",
       "                               ...                        \n",
       "65984                                                   []\n",
       "65985    [[-0.4097, -0.37167, 0.38852, -0.34947, 0.5425...\n",
       "65986    [[-0.76156, -0.012958, -0.14249, -0.5142, 1.50...\n",
       "65987    [[-0.80924, -0.030977, 0.5102, -0.75298, 0.490...\n",
       "65988    [[-0.35586, 0.5213, -0.6107, -0.30131, 0.94862...\n",
       "Name: text, Length: 65989, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se obtiene nuestro conjunto de datos X\n",
    "X = cleaned_data['text'].apply(lambda sentence: sentence_to_words_vectors(sentence))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dado que las matrices de vectores de cada oración tienen un número diferente de filas debido a que cada oración cuenta con un número diferente de palabas. Es necesario identificar el tamaño máximo de los textos que se tienen para su \"estandarización\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:08:30.301341Z",
     "start_time": "2023-05-01T01:08:30.182293Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal = deepcopy(X)\n",
    "temporal['len'] = temporal.apply(np.shape)\n",
    "\n",
    "MAX_LEN = max(temporal['len'])[0]\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dado que el tamaño máximo es 35, entonces se llevarán todas las matrices a la forma `(35, 50)`. Los valores faltantes para cada vector serán 0s en su inicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:11:58.362852Z",
     "start_time": "2023-05-01T01:11:53.413029Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 20:53:42.673625: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-01 20:53:44.945779: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/yonosoysantiago/miniconda3/envs/tf211_conda/lib/\n",
      "2023-05-01 20:53:44.946258: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/yonosoysantiago/miniconda3/envs/tf211_conda/lib/\n",
      "2023-05-01 20:53:44.946283: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_ = tf.keras.utils.pad_sequences(X, maxlen=MAX_LEN, dtype='float32')\n",
    "# X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:12:03.087480Z",
     "start_time": "2023-05-01T01:12:03.061449Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65989, 35, 50)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:12:06.580315Z",
     "start_time": "2023-05-01T01:12:06.539900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 50)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:12:09.081556Z",
     "start_time": "2023-05-01T01:12:09.056503Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       ...,\n",
       "       [-0.20492 , -0.47264 , -0.24182 , ..., -0.58691 , -0.31341 ,\n",
       "        -0.20058 ],\n",
       "       [-0.081298, -0.18447 , -0.20424 , ..., -0.027863,  0.64354 ,\n",
       "         0.59983 ],\n",
       "       [ 0.70504 ,  0.18255 , -0.75188 , ..., -0.13137 , -0.41208 ,\n",
       "        -0.092147]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## División Entrenamiento-Validación-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:12:40.748468Z",
     "start_time": "2023-05-01T01:12:39.779816Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X_, y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Embedding, Lambda, LSTM, Flatten, Dense, Input, Dropout, Bidirectional, GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from kerastuner import RandomSearch, HyperParameters\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "def print_hyperparameters(json_data):\n",
    "    values = json_data[\"values\"]\n",
    "    \n",
    "    for key, value in sorted(values.items()):\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-5)\n",
    "cp = ModelCheckpoint('saved/', save_best_only=True)\n",
    "\n",
    "callbacks = [cp, early_stopping, reduce_lr]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from ./saved/fine_tuned/HP_LSTM_Glove_text/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 8\n",
      "lstm_units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
      "lstm_dropout (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "lstm_units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "lstm_dropout_2 (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "dense_units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "dense_dropout_1 (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "dense_units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.001, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(MAX_LEN, 50)))\n",
    "\n",
    "    # Hiperparámetros para LSTM 1\n",
    "    lstm_units = hp.Int(\"lstm_units_1\", min_value=128, max_value=256, step=32)\n",
    "    lstm_dropout = hp.Float(\"lstm_dropout\", min_value=0.1, max_value=0.5, step=0.1)\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(lstm_units, return_sequences=True, dropout=lstm_dropout, recurrent_dropout=lstm_dropout)))\n",
    "\n",
    "    # Hiperparámetros para LSTM 2\n",
    "    lstm_units = hp.Int(\"lstm_units_2\", min_value=64, max_value=128, step=32)\n",
    "    lstm_dropout = hp.Float(\"lstm_dropout_2\", min_value=0.1, max_value=0.5, step=0.1)\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(lstm_units, return_sequences=True, dropout=lstm_dropout, recurrent_dropout=lstm_dropout)))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "\n",
    "    # Hiperparámetros para capa densa 1\n",
    "    dense_units = hp.Int(\"dense_units_1\", min_value=32, max_value=128, step=32)\n",
    "    dense_dropout = hp.Float(\"dense_dropout_1\", min_value=0.1, max_value=0.5, step=0.1)\n",
    "    \n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Dropout(dense_dropout))\n",
    "\n",
    "    # Hiperparámetros para capa densa 2\n",
    "    dense_units = hp.Int(\"dense_units_2\", min_value=32, max_value=128, step=32)\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "\n",
    "    # Salida del modelo\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Hiperparámetros para el optimizador (En otras pruebas se vio que Adam era el mejor)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-3, sampling=\"LOG\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define el objeto de búsqueda aleatoria\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=20,  # Número de modelos a probar\n",
    "    executions_per_trial=1,\n",
    "    directory='./saved/fine_tuned/',\n",
    "    project_name='HP_LSTM_Glove_text'\n",
    ")\n",
    "\n",
    "# Resumen de la búsqueda\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=1024\n",
    "tuner.search(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados:\n",
      "{'space': [{'class_name': 'Int', 'config': {'name': 'lstm_units_1', 'default': None, 'conditions': [], 'min_value': 128, 'max_value': 256, 'step': 32, 'sampling': 'linear'}}, {'class_name': 'Float', 'config': {'name': 'lstm_dropout', 'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'lstm_units_2', 'default': None, 'conditions': [], 'min_value': 64, 'max_value': 128, 'step': 32, 'sampling': 'linear'}}, {'class_name': 'Float', 'config': {'name': 'lstm_dropout_2', 'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'dense_units_1', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}}, {'class_name': 'Float', 'config': {'name': 'dense_dropout_1', 'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'dense_units_2', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}}, {'class_name': 'Float', 'config': {'name': 'learning_rate', 'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.001, 'step': None, 'sampling': 'log'}}], 'values': {'lstm_units_1': 224, 'lstm_dropout': 0.30000000000000004, 'lstm_units_2': 96, 'lstm_dropout_2': 0.4, 'dense_units_1': 128, 'dense_dropout_1': 0.30000000000000004, 'dense_units_2': 96, 'learning_rate': 0.0005820326357694493}}\n"
     ]
    }
   ],
   "source": [
    "best_hp_gloveLstm = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(best_hp_gloveLstm.get_config())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:14:45.215606Z",
     "start_time": "2023-05-01T01:14:43.478672Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Embedding, LSTM, Flatten, Dense, Input, Dropout, Bidirectional, GlobalMaxPooling1D\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Input(shape=(MAX_LEN, 50)))\n",
    "# model.add(Bidirectional(LSTM(128, return_sequences=True, dropout=0.25, recurrent_dropout=0.25)))\n",
    "# model.add(Bidirectional(LSTM(64, return_sequences=True, dropout=0.25, recurrent_dropout=0.25)))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:26:05.211462Z",
     "start_time": "2023-05-01T01:25:53.128122Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 20:53:47.812328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:47.812540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:47.926150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:47.926649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:47.927015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:47.927372: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:47.929517: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-01 20:53:48.132943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:48.133173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:48.133352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:48.133518: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:48.133680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:48.133842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:49.868180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:49.868464: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:49.869331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:49.869482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:49.869620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:49.870233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5681 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-05-01 20:53:49.870469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 20:53:49.870576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 2617 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:06:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "lstm_basic_model = load_model('saved/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:26:11.168631Z",
     "start_time": "2023-05-01T01:26:05.216463Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 20:53:55.191498: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43/413 [==>...........................] - ETA: 1s - loss: 1.8443 - accuracy: 0.2493"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 20:53:56.502317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 4s 3ms/step - loss: 1.8402 - accuracy: 0.2466\n"
     ]
    }
   ],
   "source": [
    "score = lstm_basic_model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T01:26:11.257149Z",
     "start_time": "2023-05-01T01:26:11.092632Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.2466282844543457\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy:', score[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## GloVe-LSTM-DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T19:38:52.074201Z",
     "start_time": "2023-04-30T19:38:50.734201Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_dropout_dense = Sequential(name='Lstm-dout-dense')\n",
    "lstm_dropout_dense.add(Input(shape=(MAX_LEN, 50)))\n",
    "lstm_dropout_dense.add(LSTM(64, return_sequences=True))\n",
    "lstm_dropout_dense.add(Dropout(0.2))\n",
    "lstm_dropout_dense.add(LSTM(32))\n",
    "lstm_dropout_dense.add(Flatten())\n",
    "lstm_dropout_dense.add(Dense(128, activation='relu'))\n",
    "lstm_dropout_dense.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from ./saved/fine_tuned/HP_LSTM_dropout_dense/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 5\n",
      "lstm_units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "dropout_rate (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "lstm_units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n",
      "dense_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.001, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from kerastuner import RandomSearch, HyperParameters\n",
    "\n",
    "def build_model_gloveLstmDo(hp):\n",
    "    model = Sequential(name='GloVe-LSTM-DO')\n",
    "    model.add(Input(shape=(MAX_LEN, 50)))\n",
    "    \n",
    "    # Hiperparámetros para la primera capa LSTM\n",
    "    lstm_units_1 = hp.Int(\"lstm_units_1\", min_value=32, max_value=128, step=32)\n",
    "    model.add(LSTM(lstm_units_1, return_sequences=True))\n",
    "    \n",
    "    # Hiperparámetros para Dropout\n",
    "    dropout_rate = hp.Float(\"dropout_rate\", min_value=0.1, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Hiperparámetros para la segunda capa LSTM\n",
    "    lstm_units_2 = hp.Int(\"lstm_units_2\", min_value=16, max_value=64, step=16)\n",
    "    model.add(LSTM(lstm_units_2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Hiperparámetros para la capa Densa\n",
    "    dense_units = hp.Int(\"dense_units\", min_value=32, max_value=256, step=32)\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Hiperparámetros para el optimizador\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-3, sampling=\"LOG\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "gloveLstmDoTuner = RandomSearch(\n",
    "    build_model_gloveLstmDo,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=20,  # Número de modelos a probar\n",
    "    executions_per_trial=1,\n",
    "    directory='./saved/fine_tuned/',\n",
    "    project_name='HP_LSTM_dropout_dense'\n",
    ")\n",
    "\n",
    "# Resumen de la búsqueda\n",
    "gloveLstmDoTuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Realiza la búsqueda\n",
    "gloveLstmDoTuner.search(X_train, y_train,\n",
    "             epochs=10,\n",
    "             validation_split=0.1,\n",
    "             batch_size=4096,\n",
    "             callbacks=callbacks)\n",
    "\n",
    "best_hp_gloveLstmDo = gloveLstmDoTuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T19:38:53.773316Z",
     "start_time": "2023-04-30T19:38:53.717317Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lstm_dropout_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T19:49:18.525348Z",
     "start_time": "2023-04-30T19:49:18.260182Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lstm_dropout_dense.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T19:49:02.031330Z",
     "start_time": "2023-04-30T19:49:01.983319Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T20:33:54.839842Z",
     "start_time": "2023-04-30T19:49:23.531267Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# history_2 = lstm_dropout_dense.fit(X_train, y_train,\n",
    "#                     validation_split=0.2, epochs=10,\n",
    "#                     batch_size=BATCH_SIZE,\n",
    "#                     callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T20:35:26.123724Z",
     "start_time": "2023-04-30T20:34:57.096320Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# score = lstm_dropout_dense.evaluate(X_test, y_test, verbose=1)\n",
    "# print('Test Accuracy:', score[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3LSTM-DO-CNN-Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Conv1D, MaxPooling1D\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Input, LSTM, Dropout, Flatten, Dense\n",
    "# from keras.optimizers import Adam, RMSprop, SGD\n",
    "# from kerastuner import RandomSearch, HyperParameters\n",
    "\n",
    "# lstm3_do_cnn_dense = Sequential(name='3LSTM-DO-CNN-Dense')\n",
    "# lstm3_do_cnn_dense.add(Input(shape=(MAX_LEN, 50)))\n",
    "\n",
    "# #LSTM\n",
    "# lstm3_do_cnn_dense.add(LSTM(256, name='LSTM1', return_sequences=True))\n",
    "# lstm3_do_cnn_dense.add(Dropout(0.2, name='DO1'))\n",
    "\n",
    "# lstm3_do_cnn_dense.add(LSTM(128, name='LSTM2', return_sequences=True))\n",
    "# lstm3_do_cnn_dense.add(Dropout(0.2, name='DO2'))\n",
    "\n",
    "# lstm3_do_cnn_dense.add(LSTM(64, name='LSTM3', return_sequences=True))\n",
    "# lstm3_do_cnn_dense.add(Dropout(0.2, name='DO3'))\n",
    "\n",
    "# #CNN\n",
    "# lstm3_do_cnn_dense.add(Conv1D(128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "# lstm3_do_cnn_dense.add(MaxPooling1D(pool_size=3, strides=2, padding='same'))\n",
    "# lstm3_do_cnn_dense.add(Dropout(0.2))\n",
    "# lstm3_do_cnn_dense.add(Flatten(name='F1'))\n",
    "\n",
    "# #Fully connected\n",
    "# lstm3_do_cnn_dense.add(Dense(64, activation='relu'))\n",
    "# lstm3_do_cnn_dense.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# lstm3_do_cnn_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_gloveLstmDoCnn(hp):\n",
    "    model = Sequential(name='3LSTM-DO-CNN-Dense')\n",
    "    model.add(Input(shape=(MAX_LEN, 50)))\n",
    "\n",
    "    # Hiperparámetros para la primera capa LSTM\n",
    "    lstm_units_1 = hp.Int(\"lstm_units_1\", min_value=128, max_value=512, step=32)\n",
    "    model.add(LSTM(lstm_units_1, name='LSTM1', return_sequences=True))\n",
    "    lstm_dropout_1 = hp.Float(\"lstm_dropout_1\", min_value=0.1, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(lstm_dropout_1, name='DO1'))\n",
    "\n",
    "    # Hiperparámetros para la segunda capa LSTM\n",
    "    lstm_units_2 = hp.Int(\"lstm_units_2\", min_value=64, max_value=256, step=32)\n",
    "    model.add(LSTM(lstm_units_2, name='LSTM2', return_sequences=True))\n",
    "    lstm_dropout_2 = hp.Float(\"lstm_dropout_2\", min_value=0.1, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(lstm_dropout_2, name='DO2'))\n",
    "\n",
    "    # Hiperparámetros para la tercera capa LSTM\n",
    "    lstm_units_3 = hp.Int(\"lstm_units_3\", min_value=32, max_value=128, step=16)\n",
    "    model.add(LSTM(lstm_units_3, name='LSTM3', return_sequences=True))\n",
    "    lstm_dropout_3 = hp.Float(\"lstm_dropout_3\", min_value=0.1, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(lstm_dropout_3, name='DO3'))\n",
    "\n",
    "    # Hiperparámetros para la capa Conv1D\n",
    "    conv_filters = hp.Int(\"conv_filters\", min_value=32, max_value=256, step=32)\n",
    "    model.add(Conv1D(conv_filters, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "    \n",
    "    model.add(MaxPooling1D(pool_size=3, strides=2, padding='same'))\n",
    "\n",
    "    cnn_dropout = hp.Float(\"cnn_dropout\", min_value=0.1, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(cnn_dropout))\n",
    "    \n",
    "    model.add(Flatten(name='F1'))\n",
    "\n",
    "    # Hiperparámetros para la capa Densa\n",
    "    dense_units = hp.Int(\"dense_units\", min_value=32, max_value=256, step=32)\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Hiperparámetros para el optimizador\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-3, sampling=\"LOG\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from ./saved/fine_tuned/HP_3LSTM-DO-CNN-Dense/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 10\n",
      "lstm_units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "lstm_dropout_1 (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "lstm_units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
      "lstm_dropout_2 (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "lstm_units_3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': 'linear'}\n",
      "lstm_dropout_3 (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "conv_filters (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
      "cnn_dropout (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "dense_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.001, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model_gloveLstmDoCnn,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=20,  # Número de modelos a probar\n",
    "    executions_per_trial=1,\n",
    "    directory='./saved/fine_tuned/',\n",
    "    project_name='HP_3LSTM-DO-CNN-Dense'\n",
    ")\n",
    "\n",
    "# Resumen de la búsqueda\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "Mejores hiperparámetros encontrados:\n",
      "cnn_dropout: 0.5\n",
      "conv_filters: 256\n",
      "dense_units: 224\n",
      "learning_rate: 0.0009359146486726661\n",
      "lstm_dropout_1: 0.30000000000000004\n",
      "lstm_dropout_2: 0.30000000000000004\n",
      "lstm_dropout_3: 0.4\n",
      "lstm_units_1: 384\n",
      "lstm_units_2: 256\n",
      "lstm_units_3: 32\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=4096\n",
    "tuner.search(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "best_hp_gloveLstmDoCnn = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print_hyperparameters(best_hp_gloveLstmDoCnn.get_config())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO 1\n",
      "dense_dropout_1: 0.30000000000000004\n",
      "dense_units_1: 128\n",
      "dense_units_2: 96\n",
      "learning_rate: 0.0005820326357694493\n",
      "lstm_dropout: 0.30000000000000004\n",
      "lstm_dropout_2: 0.4\n",
      "lstm_units_1: 224\n",
      "lstm_units_2: 96\n",
      " ==================================================== \n",
      "MODELO 2\n",
      "dense_units: 128\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.0008080792741293362\n",
      "lstm_units_1: 128\n",
      "lstm_units_2: 32\n",
      " ==================================================== \n",
      "MODELO 3\n",
      "cnn_dropout: 0.5\n",
      "conv_filters: 256\n",
      "dense_units: 224\n",
      "learning_rate: 0.0009359146486726661\n",
      "lstm_dropout_1: 0.30000000000000004\n",
      "lstm_dropout_2: 0.30000000000000004\n",
      "lstm_dropout_3: 0.4\n",
      "lstm_units_1: 384\n",
      "lstm_units_2: 256\n",
      "lstm_units_3: 32\n"
     ]
    }
   ],
   "source": [
    "print(\"MODELO 1\")\n",
    "print_hyperparameters(best_hp_gloveLstm.get_config())\n",
    "print(\" ==================================================== \")\n",
    "print(\"MODELO 2\")\n",
    "print_hyperparameters(best_hp_gloveLstmDo.get_config())\n",
    "print(\" ==================================================== \")\n",
    "print(\"MODELO 3\")\n",
    "print_hyperparameters(best_hp_gloveLstmDoCnn.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model_1(hyper_parameters):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(MAX_LEN, 50)))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(hyper_parameters.get('lstm_units_1'), \n",
    "                                 return_sequences=True, \n",
    "                                 dropout=hyper_parameters.get('lstm_dropout'), \n",
    "                                 recurrent_dropout=hyper_parameters.get('lstm_dropout'))))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(hyper_parameters.get('lstm_units_2'), \n",
    "                                 return_sequences=True, \n",
    "                                 dropout=hyper_parameters.get('lstm_dropout_2'), \n",
    "                                 recurrent_dropout=hyper_parameters.get('lstm_dropout_2'))))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(hyper_parameters.get('dense_units_1'), activation='relu'))\n",
    "    model.add(Dropout(hyper_parameters.get('dense_dropout_1')))\n",
    "    model.add(Dense(hyper_parameters.get('dense_units_2'), activation='relu'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 20:54:06.574453: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x59e012d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-01 20:54:06.574474: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n",
      "2023-05-01 20:54:06.574478: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2023-05-01 20:54:06.578076: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-01 20:54:06.690376: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 1.7459 - accuracy: 0.3214INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 30s 543ms/step - loss: 1.7459 - accuracy: 0.3214 - val_loss: 1.6416 - val_accuracy: 0.3747 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6379 - accuracy: 0.3746INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 530ms/step - loss: 1.6379 - accuracy: 0.3746 - val_loss: 1.5913 - val_accuracy: 0.3936 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5977 - accuracy: 0.3910INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 528ms/step - loss: 1.5977 - accuracy: 0.3910 - val_loss: 1.5675 - val_accuracy: 0.4003 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5706 - accuracy: 0.4030INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 531ms/step - loss: 1.5706 - accuracy: 0.4030 - val_loss: 1.5409 - val_accuracy: 0.4157 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5443 - accuracy: 0.4137INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 529ms/step - loss: 1.5443 - accuracy: 0.4137 - val_loss: 1.5100 - val_accuracy: 0.4317 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5215 - accuracy: 0.4241INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 23s 546ms/step - loss: 1.5215 - accuracy: 0.4241 - val_loss: 1.4921 - val_accuracy: 0.4357 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5035 - accuracy: 0.4308INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 23s 549ms/step - loss: 1.5035 - accuracy: 0.4308 - val_loss: 1.4641 - val_accuracy: 0.4443 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4805 - accuracy: 0.4404INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 539ms/step - loss: 1.4805 - accuracy: 0.4404 - val_loss: 1.4457 - val_accuracy: 0.4527 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4644 - accuracy: 0.4465INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 533ms/step - loss: 1.4644 - accuracy: 0.4465 - val_loss: 1.4369 - val_accuracy: 0.4555 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4479 - accuracy: 0.4542INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 534ms/step - loss: 1.4479 - accuracy: 0.4542 - val_loss: 1.4212 - val_accuracy: 0.4678 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 11s 268ms/step - loss: 1.4329 - accuracy: 0.4608 - val_loss: 1.4224 - val_accuracy: 0.4676 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4168 - accuracy: 0.4651INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 524ms/step - loss: 1.4168 - accuracy: 0.4651 - val_loss: 1.3952 - val_accuracy: 0.4755 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4030 - accuracy: 0.4703INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 539ms/step - loss: 1.4030 - accuracy: 0.4703 - val_loss: 1.3842 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3848 - accuracy: 0.4792INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 534ms/step - loss: 1.3848 - accuracy: 0.4792 - val_loss: 1.3785 - val_accuracy: 0.4837 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3727 - accuracy: 0.4810INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 524ms/step - loss: 1.3727 - accuracy: 0.4810 - val_loss: 1.3679 - val_accuracy: 0.4881 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3614 - accuracy: 0.4891INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 23s 554ms/step - loss: 1.3614 - accuracy: 0.4891 - val_loss: 1.3564 - val_accuracy: 0.4926 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 1.3476 - accuracy: 0.4929 - val_loss: 1.3685 - val_accuracy: 0.4911 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3356 - accuracy: 0.4983INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 23s 556ms/step - loss: 1.3356 - accuracy: 0.4983 - val_loss: 1.3547 - val_accuracy: 0.4964 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3253 - accuracy: 0.5015INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 538ms/step - loss: 1.3253 - accuracy: 0.5015 - val_loss: 1.3485 - val_accuracy: 0.4962 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3148 - accuracy: 0.5079INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 534ms/step - loss: 1.3148 - accuracy: 0.5079 - val_loss: 1.3329 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3014 - accuracy: 0.5086INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 532ms/step - loss: 1.3014 - accuracy: 0.5086 - val_loss: 1.3261 - val_accuracy: 0.5053 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 11s 268ms/step - loss: 1.2925 - accuracy: 0.5140 - val_loss: 1.3331 - val_accuracy: 0.5082 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2863 - accuracy: 0.5177INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 23s 544ms/step - loss: 1.2863 - accuracy: 0.5177 - val_loss: 1.3219 - val_accuracy: 0.5063 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2712 - accuracy: 0.5228INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 541ms/step - loss: 1.2712 - accuracy: 0.5228 - val_loss: 1.3204 - val_accuracy: 0.5080 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2680 - accuracy: 0.5248INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 540ms/step - loss: 1.2680 - accuracy: 0.5248 - val_loss: 1.3189 - val_accuracy: 0.5105 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 11s 269ms/step - loss: 1.2538 - accuracy: 0.5304 - val_loss: 1.3238 - val_accuracy: 0.5115 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2457 - accuracy: 0.5317INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 22s 531ms/step - loss: 1.2457 - accuracy: 0.5317 - val_loss: 1.3147 - val_accuracy: 0.5167 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 11s 272ms/step - loss: 1.2310 - accuracy: 0.5392 - val_loss: 1.3182 - val_accuracy: 0.5128 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2273 - accuracy: 0.5400INFO:tensorflow:Assets written to: saved/assets\n",
      "42/42 [==============================] - 23s 546ms/step - loss: 1.2273 - accuracy: 0.5400 - val_loss: 1.3085 - val_accuracy: 0.5124 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 12s 276ms/step - loss: 1.2203 - accuracy: 0.5409 - val_loss: 1.3153 - val_accuracy: 0.5143 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f38242e0a60>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_gloveLstm = best_model_1(best_hp_gloveLstm)\n",
    "best_model_gloveLstm.fit(X_train, y_train,\n",
    "             epochs=30,\n",
    "             validation_split=0.2,\n",
    "             batch_size=1024,\n",
    "             callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model_2(hp):\n",
    "    model = Sequential(name='GloVe-LSTM-DO')\n",
    "    model.add(Input(shape=(MAX_LEN, 50)))\n",
    "    \n",
    "    # Hiperparámetros para la primera capa LSTM\n",
    "    lstm_units_1 = hp.get(\"lstm_units_1\")\n",
    "    model.add(LSTM(lstm_units_1, return_sequences=True))\n",
    "    \n",
    "    # Hiperparámetros para Dropout\n",
    "    dropout_rate = hp.get(\"dropout_rate\")\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Hiperparámetros para la segunda capa LSTM\n",
    "    lstm_units_2 = hp.get(\"lstm_units_2\")\n",
    "    model.add(LSTM(lstm_units_2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Hiperparámetros para la capa Densa\n",
    "    dense_units = hp.get(\"dense_units\")\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Hiperparámetros para el optimizador\n",
    "    learning_rate = hp.get(\"learning_rate\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - 4s 94ms/step - loss: 1.8823 - accuracy: 0.2309 - val_loss: 1.8294 - val_accuracy: 0.2524 - lr: 8.0808e-04\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.8082 - accuracy: 0.2792 - val_loss: 1.7805 - val_accuracy: 0.3122 - lr: 8.0808e-04\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.7589 - accuracy: 0.3134 - val_loss: 1.7376 - val_accuracy: 0.3338 - lr: 8.0808e-04\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.7116 - accuracy: 0.3513 - val_loss: 1.6981 - val_accuracy: 0.3555 - lr: 8.0808e-04\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.6707 - accuracy: 0.3661 - val_loss: 1.6676 - val_accuracy: 0.3648 - lr: 8.0808e-04\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.6428 - accuracy: 0.3735 - val_loss: 1.6444 - val_accuracy: 0.3733 - lr: 8.0808e-04\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.6232 - accuracy: 0.3820 - val_loss: 1.6330 - val_accuracy: 0.3769 - lr: 8.0808e-04\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.6089 - accuracy: 0.3869 - val_loss: 1.6203 - val_accuracy: 0.3838 - lr: 8.0808e-04\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.5955 - accuracy: 0.3929 - val_loss: 1.6067 - val_accuracy: 0.3855 - lr: 8.0808e-04\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.5847 - accuracy: 0.3948 - val_loss: 1.5998 - val_accuracy: 0.3887 - lr: 8.0808e-04\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.5739 - accuracy: 0.4005 - val_loss: 1.5872 - val_accuracy: 0.3964 - lr: 8.0808e-04\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 1.5639 - accuracy: 0.4047 - val_loss: 1.5804 - val_accuracy: 0.3964 - lr: 8.0808e-04\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.5572 - accuracy: 0.4068 - val_loss: 1.5735 - val_accuracy: 0.3976 - lr: 8.0808e-04\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.5446 - accuracy: 0.4135 - val_loss: 1.5659 - val_accuracy: 0.4085 - lr: 8.0808e-04\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.5376 - accuracy: 0.4148 - val_loss: 1.5594 - val_accuracy: 0.4060 - lr: 8.0808e-04\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.5284 - accuracy: 0.4184 - val_loss: 1.5529 - val_accuracy: 0.4088 - lr: 8.0808e-04\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.5177 - accuracy: 0.4240 - val_loss: 1.5428 - val_accuracy: 0.4137 - lr: 8.0808e-04\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.5094 - accuracy: 0.4274 - val_loss: 1.5341 - val_accuracy: 0.4180 - lr: 8.0808e-04\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.5026 - accuracy: 0.4306 - val_loss: 1.5330 - val_accuracy: 0.4168 - lr: 8.0808e-04\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.4946 - accuracy: 0.4366 - val_loss: 1.5224 - val_accuracy: 0.4227 - lr: 8.0808e-04\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.4854 - accuracy: 0.4400 - val_loss: 1.5145 - val_accuracy: 0.4259 - lr: 8.0808e-04\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.4797 - accuracy: 0.4427 - val_loss: 1.5153 - val_accuracy: 0.4236 - lr: 8.0808e-04\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 1.4752 - accuracy: 0.4443 - val_loss: 1.5062 - val_accuracy: 0.4265 - lr: 8.0808e-04\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.4657 - accuracy: 0.4472 - val_loss: 1.5049 - val_accuracy: 0.4275 - lr: 8.0808e-04\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.4607 - accuracy: 0.4495 - val_loss: 1.4962 - val_accuracy: 0.4380 - lr: 8.0808e-04\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.4536 - accuracy: 0.4529 - val_loss: 1.4902 - val_accuracy: 0.4341 - lr: 8.0808e-04\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.4478 - accuracy: 0.4541 - val_loss: 1.4908 - val_accuracy: 0.4383 - lr: 8.0808e-04\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.4402 - accuracy: 0.4587 - val_loss: 1.4846 - val_accuracy: 0.4399 - lr: 8.0808e-04\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.4340 - accuracy: 0.4629 - val_loss: 1.4774 - val_accuracy: 0.4437 - lr: 8.0808e-04\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.4278 - accuracy: 0.4638 - val_loss: 1.4775 - val_accuracy: 0.4407 - lr: 8.0808e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f376018e650>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_gloveLstmDo = best_model_2(best_hp_gloveLstmDo)\n",
    "best_model_gloveLstmDo.fit(X_train, y_train,\n",
    "             epochs=30,\n",
    "             validation_split=0.2,\n",
    "             batch_size=4093,\n",
    "             callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model_3(hp):\n",
    "    model = Sequential(name='3LSTM-DO-CNN-Dense')\n",
    "    model.add(Input(shape=(MAX_LEN, 50)))\n",
    "\n",
    "    # Hiperparámetros para la primera capa LSTM\n",
    "    lstm_units_1 = hp.get(\"lstm_units_1\")\n",
    "    model.add(LSTM(lstm_units_1, name='LSTM1', return_sequences=True))\n",
    "    lstm_dropout_1 = hp.get(\"lstm_dropout_1\")\n",
    "    model.add(Dropout(lstm_dropout_1, name='DO1'))\n",
    "\n",
    "    # Hiperparámetros para la segunda capa LSTM\n",
    "    lstm_units_2 = hp.get(\"lstm_units_2\")\n",
    "    model.add(LSTM(lstm_units_2, name='LSTM2', return_sequences=True))\n",
    "    lstm_dropout_2 = hp.get(\"lstm_dropout_2\")\n",
    "    model.add(Dropout(lstm_dropout_2, name='DO2'))\n",
    "\n",
    "    # Hiperparámetros para la tercera capa LSTM\n",
    "    lstm_units_3 = hp.get(\"lstm_units_3\")\n",
    "    model.add(LSTM(lstm_units_3, name='LSTM3', return_sequences=True))\n",
    "    lstm_dropout_3 = hp.get(\"lstm_dropout_3\")\n",
    "    model.add(Dropout(lstm_dropout_3, name='DO3'))\n",
    "\n",
    "    # Hiperparámetros para la capa Conv1D\n",
    "    conv_filters = hp.get(\"conv_filters\")\n",
    "    model.add(Conv1D(conv_filters, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "    \n",
    "    model.add(MaxPooling1D(pool_size=3, strides=2, padding='same'))\n",
    "\n",
    "    cnn_dropout = hp.get(\"cnn_dropout\")\n",
    "    model.add(Dropout(cnn_dropout))\n",
    "    \n",
    "    model.add(Flatten(name='F1'))\n",
    "\n",
    "    # Hiperparámetros para la capa Densa\n",
    "    dense_units = hp.get(\"dense_units\")\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Hiperparámetros para el optimizador\n",
    "    learning_rate = hp.get(\"learning_rate\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - 8s 258ms/step - loss: 1.8540 - accuracy: 0.2409 - val_loss: 1.8160 - val_accuracy: 0.2948 - lr: 9.3591e-04\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 2s 181ms/step - loss: 1.7768 - accuracy: 0.2994 - val_loss: 1.7688 - val_accuracy: 0.3132 - lr: 9.3591e-04\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 2s 181ms/step - loss: 1.7234 - accuracy: 0.3353 - val_loss: 1.7023 - val_accuracy: 0.3459 - lr: 9.3591e-04\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 2s 181ms/step - loss: 1.6709 - accuracy: 0.3609 - val_loss: 1.6615 - val_accuracy: 0.3720 - lr: 9.3591e-04\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 1.6335 - accuracy: 0.3777 - val_loss: 1.6290 - val_accuracy: 0.3815 - lr: 9.3591e-04\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 2s 181ms/step - loss: 1.6008 - accuracy: 0.3877 - val_loss: 1.6007 - val_accuracy: 0.3916 - lr: 9.3591e-04\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 2s 185ms/step - loss: 1.5773 - accuracy: 0.3968 - val_loss: 1.5894 - val_accuracy: 0.3985 - lr: 9.3591e-04\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 1.5623 - accuracy: 0.4025 - val_loss: 1.5672 - val_accuracy: 0.4102 - lr: 9.3591e-04\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 1.5462 - accuracy: 0.4125 - val_loss: 1.5550 - val_accuracy: 0.4143 - lr: 9.3591e-04\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 2s 184ms/step - loss: 1.5339 - accuracy: 0.4198 - val_loss: 1.5413 - val_accuracy: 0.4185 - lr: 9.3591e-04\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 1.5193 - accuracy: 0.4245 - val_loss: 1.5383 - val_accuracy: 0.4171 - lr: 9.3591e-04\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 1.5130 - accuracy: 0.4303 - val_loss: 1.5209 - val_accuracy: 0.4269 - lr: 9.3591e-04\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 2s 183ms/step - loss: 1.4946 - accuracy: 0.4357 - val_loss: 1.5176 - val_accuracy: 0.4297 - lr: 9.3591e-04\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 1.4818 - accuracy: 0.4431 - val_loss: 1.5071 - val_accuracy: 0.4356 - lr: 9.3591e-04\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 2s 185ms/step - loss: 1.4730 - accuracy: 0.4477 - val_loss: 1.4997 - val_accuracy: 0.4377 - lr: 9.3591e-04\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 1.4572 - accuracy: 0.4514 - val_loss: 1.4855 - val_accuracy: 0.4448 - lr: 9.3591e-04\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 1.4492 - accuracy: 0.4538 - val_loss: 1.4807 - val_accuracy: 0.4457 - lr: 9.3591e-04\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 1.4428 - accuracy: 0.4585 - val_loss: 1.4884 - val_accuracy: 0.4414 - lr: 9.3591e-04\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 2s 186ms/step - loss: 1.4351 - accuracy: 0.4604 - val_loss: 1.4677 - val_accuracy: 0.4550 - lr: 9.3591e-04\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 1.4190 - accuracy: 0.4665 - val_loss: 1.4565 - val_accuracy: 0.4583 - lr: 9.3591e-04\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 1.4039 - accuracy: 0.4732 - val_loss: 1.4537 - val_accuracy: 0.4615 - lr: 9.3591e-04\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 2s 183ms/step - loss: 1.3932 - accuracy: 0.4778 - val_loss: 1.4431 - val_accuracy: 0.4617 - lr: 9.3591e-04\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 1.3821 - accuracy: 0.4812 - val_loss: 1.4431 - val_accuracy: 0.4610 - lr: 9.3591e-04\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 2s 184ms/step - loss: 1.3780 - accuracy: 0.4824 - val_loss: 1.4432 - val_accuracy: 0.4599 - lr: 9.3591e-04\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 1.3705 - accuracy: 0.4864 - val_loss: 1.4390 - val_accuracy: 0.4597 - lr: 9.3591e-04\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 2s 184ms/step - loss: 1.3539 - accuracy: 0.4916 - val_loss: 1.4248 - val_accuracy: 0.4713 - lr: 9.3591e-04\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 2s 185ms/step - loss: 1.3424 - accuracy: 0.4978 - val_loss: 1.4221 - val_accuracy: 0.4689 - lr: 9.3591e-04\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 2s 183ms/step - loss: 1.3346 - accuracy: 0.4993 - val_loss: 1.4331 - val_accuracy: 0.4701 - lr: 9.3591e-04\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 2s 183ms/step - loss: 1.3231 - accuracy: 0.5057 - val_loss: 1.4244 - val_accuracy: 0.4758 - lr: 9.3591e-04\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 1.3146 - accuracy: 0.5096 - val_loss: 1.4402 - val_accuracy: 0.4652 - lr: 9.3591e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3540194280>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_gloveLstmDoCnn = best_model_3(best_hp_gloveLstmDoCnn)\n",
    "best_model_gloveLstmDoCnn.fit(X_train, y_train,\n",
    "             epochs=30,\n",
    "             validation_split=0.2,\n",
    "             batch_size=4093,\n",
    "             callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove LSTM\n",
      "413/413 [==============================] - 13s 32ms/step - loss: 1.3057 - accuracy: 0.5175\n",
      "Test Accuracy: 0.5175026655197144\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove LSTM\")\n",
    "score = best_model_gloveLstm.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove LSTM Do\n",
      "413/413 [==============================] - 1s 2ms/step - loss: 1.4628 - accuracy: 0.4505\n",
      "Test Accuracy: 0.4505228102207184\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove LSTM Do\")\n",
    "score = best_model_gloveLstmDo.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove LSTM Do Cnn\n",
      "413/413 [==============================] - 1s 3ms/step - loss: 1.4320 - accuracy: 0.4698\n",
      "Test Accuracy: 0.46976813673973083\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove LSTM Do Cnn\")\n",
    "score = best_model_gloveLstmDoCnn.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
