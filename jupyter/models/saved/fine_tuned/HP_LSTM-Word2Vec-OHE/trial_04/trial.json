{"trial_id": "04", "hyperparameters": {"space": [{"class_name": "Int", "config": {"name": "lstm_units", "default": null, "conditions": [], "min_value": 32, "max_value": 256, "step": 32, "sampling": "linear"}}, {"class_name": "Float", "config": {"name": "lstm_dropout", "default": 0.1, "conditions": [], "min_value": 0.1, "max_value": 0.5, "step": 0.1, "sampling": "linear"}}, {"class_name": "Float", "config": {"name": "learning_rate", "default": 1e-05, "conditions": [], "min_value": 1e-05, "max_value": 0.001, "step": null, "sampling": "log"}}], "values": {"lstm_units": 256, "lstm_dropout": 0.30000000000000004, "learning_rate": 0.000949901263914378}}, "metrics": {"metrics": {}}, "score": null, "best_step": 0, "status": "FAILED", "message": "Traceback (most recent call last):\n  File \"/home/yonosoysantiago/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/yonosoysantiago/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/yonosoysantiago/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/home/yonosoysantiago/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"/home/yonosoysantiago/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py\", line 144, in fit\n    return model.fit(*args, **kwargs)\n  File \"/home/yonosoysantiago/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/yonosoysantiago/miniconda3/envs/tf211_conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n\nOOM when allocating tensor with shape[100,4096,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[PartitionedCall]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_550385]\n"}