{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Increasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente notebook presenta el proceso de incremento y limpieza de nuevos datos de texto. Igualmente, al final se realizará la unión con los 65 mil registos de texto existentes y ya procesados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de nuevos datos\n",
    "\n",
    "Para almacenar los datos que se van a ir cargando y limpiando, vamos a emplear un diccionario con los nombres de los archivos asociados a su dataset limpio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:01:10.794793Z",
     "start_time": "2023-05-14T17:01:09.139921Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = \"../data/text/raw/\"\n",
    "cleaned_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anon Disorders\n",
    "\n",
    "OJO: La siguientes celdas demoran en ejecutar porque manipula un archivo de 4GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T00:16:27.991654Z",
     "start_time": "2023-05-10T00:07:34.901376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>disorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3f21058fc8</td>\n",
       "      <td>@amirulmokhtar Exactly! We were busy buat untu...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3f21058fc8</td>\n",
       "      <td>Ternangis baca text &amp;amp; dengar call reply di...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3f21058fc8</td>\n",
       "      <td>I learn smthg very valuable today.\\n\\nWhen I w...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3f21058fc8</td>\n",
       "      <td>@MintKr Ohhh okay. So, to create more opportun...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3f21058fc8</td>\n",
       "      <td>@MintKr Perspective expanding experience tu ap...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     user_id                                               text  \\\n",
       "0           0  3f21058fc8  @amirulmokhtar Exactly! We were busy buat untu...   \n",
       "1           1  3f21058fc8  Ternangis baca text &amp; dengar call reply di...   \n",
       "2           2  3f21058fc8  I learn smthg very valuable today.\\n\\nWhen I w...   \n",
       "3           3  3f21058fc8  @MintKr Ohhh okay. So, to create more opportun...   \n",
       "4           4  3f21058fc8  @MintKr Perspective expanding experience tu ap...   \n",
       "\n",
       "  disorder  \n",
       "0  anxiety  \n",
       "1  anxiety  \n",
       "2  anxiety  \n",
       "3  anxiety  \n",
       "4  anxiety  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anon_disorder = pd.read_csv(DATA_DIR + \"anon_disorder_tweets.csv\")\n",
    "df_anon_disorder.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T00:26:08.493335Z",
     "start_time": "2023-05-10T00:24:16.771664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'disorder'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anon_disorder = df_anon_disorder.drop(columns=['Unnamed: 0', 'user_id'], axis=1)\n",
    "df_anon_disorder.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anxiety', 'depression', 'ptsd', 'borderline', 'panic', 'bipolar']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(df_anon_disorder[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpriority\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()))\n\u001b[0;32m      3\u001b[0m df_anon_disorder[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpriority\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_anon_disorder[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpriority\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mlist\u001b[39m(df_anon_disorder[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpriority\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdf_anon_disorder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "df_anon_disorder.rename(columns={'disorder': 'priority'}, inplace=True)\n",
    "print(list(df_anon_disorder['priority'].unique()))\n",
    "df_anon_disorder['priority'] = df_anon_disorder['priority'].replace(\n",
    "    list(df_anon_disorder['priority'].unique()), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T00:58:37.543135Z",
     "start_time": "2023-05-10T00:42:23.714306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32191368, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anon_disorder.dropna(inplace=True)\n",
    "df_anon_disorder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T01:00:25.712372Z",
     "start_time": "2023-05-10T01:00:25.695376Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_data['anon_disorder_tweets.csv'] = df_anon_disorder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anxious_Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:01:17.163365Z",
     "start_time": "2023-05-14T17:01:17.107248Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8460, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anxious = pd.read_csv(DATA_DIR + \"Anxious_Tweets.csv\")\n",
    "df_anxious['priority'] = [1 for i in range(df_anxious.shape[0])]\n",
    "df_anxious.rename(columns={'0': 'text'}, inplace=True)\n",
    "df_anxious.dropna(inplace=True)\n",
    "df_anxious.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_anxious.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:01:20.401661Z",
     "start_time": "2023-05-14T17:01:20.378663Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_data['Anxious_Tweets.csv'] = df_anxious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Students Anxiety and depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:01:24.001856Z",
     "start_time": "2023-05-14T17:01:22.414246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6970, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset = pd.read_excel(DATA_DIR + \"dataset.xlsx\")\n",
    "df_dataset.rename(columns={'label':'priority'}, inplace=True)\n",
    "df_dataset.dropna(inplace=True)\n",
    "df_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:01:25.068476Z",
     "start_time": "2023-05-14T17:01:25.057479Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_data['dataset.xlsx'] = df_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lonely_Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:01:27.631700Z",
     "start_time": "2023-05-14T17:01:27.586681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8460, 2)\n"
     ]
    }
   ],
   "source": [
    "def process_lonely_tweets(data_dir, cleaned_data):\n",
    "    \"\"\"\n",
    "    Procesa los datos de tweets solitarios.\n",
    "\n",
    "    :param data_dir: Directorio donde se encuentra el archivo de datos.\n",
    "    :type data_dir: str\n",
    "    :param cleaned_data: Diccionario para almacenar los datos procesados.\n",
    "    :type cleaned_data: dict\n",
    "    \"\"\"\n",
    "    file_path = data_dir + \"Lonely_Tweets.csv\"\n",
    "\n",
    "    df_lonely = pd.read_csv(file_path)\n",
    "    df_lonely['priority'] = [1 for _ in range(df_lonely.shape[0])]\n",
    "    df_lonely.rename(columns={'0': 'text'}, inplace=True)\n",
    "    df_lonely.dropna(inplace=True)\n",
    "    df_lonely.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    cleaned_data['Lonely_Tweets.csv'] = df_lonely\n",
    "    print(df_lonely.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mental_health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:01:29.855359Z",
     "start_time": "2023-05-14T17:01:29.617605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27977, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_mental_health_data(data_dir):\n",
    "    \"\"\"\n",
    "    Procesa los datos relacionados con la salud mental.\n",
    "\n",
    "    :param data_dir: Directorio donde se encuentra el archivo de datos.\n",
    "    :type data_dir: str\n",
    "    :return: DataFrame procesado.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    file_path = data_dir + \"mental_health.csv\"\n",
    "\n",
    "    df_mental_health = pd.read_csv(file_path)\n",
    "    df_mental_health.rename(columns={'label': 'priority'}, inplace=True)\n",
    "    df_mental_health.dropna(inplace=True)\n",
    "\n",
    "    return df_mental_health.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:01:31.915717Z",
     "start_time": "2023-05-14T17:01:31.901725Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_data['mental_health.csv'] = df_mental_health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal_Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:01:33.825316Z",
     "start_time": "2023-05-14T17:01:33.790344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9925, 2)\n"
     ]
    }
   ],
   "source": [
    "def process_normal_tweets_data(data_dir):\n",
    "    \"\"\"\n",
    "    Procesa los datos de tweets normales.\n",
    "\n",
    "    :param data_dir: Directorio donde se encuentra el archivo de datos.\n",
    "    :type data_dir: str\n",
    "    :return: DataFrame procesado.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    file_path = data_dir + \"Normal_Tweets.csv\"\n",
    "\n",
    "    df_normal = pd.read_csv(file_path)\n",
    "    df_normal['priority'] = [0 for _ in range(df_normal.shape[0])]\n",
    "    df_normal.rename(columns={'cleaned_text': 'text'}, inplace=True)\n",
    "    df_normal.dropna(inplace=True)\n",
    "    df_normal.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    return df_normal.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p_n_n_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:06:38.074232Z",
     "start_time": "2023-05-14T17:06:36.561232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174644, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pn = pd.read_csv(DATA_DIR + \"p_n_n_dataset.csv\")\n",
    "df_pn = df_pn[['tweet', 'label']]\n",
    "df_pn['label'] = df_pn['label'].replace(['negative'], 1)\n",
    "df_pn['label'] = df_pn['label'].replace(['neutral', 'positive'], 0)\n",
    "df_pn.rename(columns={'label':'priority', 'tweet': 'text'}, inplace=True)\n",
    "df_pn.dropna(inplace=True)\n",
    "df_pn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:06:39.529884Z",
     "start_time": "2023-05-14T17:06:39.494882Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_data['p_n_n_dataset.csv'] = df_pn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stressed_Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:01:47.968165Z",
     "start_time": "2023-05-14T17:01:47.909543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8535, 2)\n"
     ]
    }
   ],
   "source": [
    "def process_stressed_tweets_data(data_dir):\n",
    "    \"\"\"\n",
    "    Procesa los datos de tweets estresados.\n",
    "\n",
    "    :param data_dir: Directorio donde se encuentra el archivo de datos.\n",
    "    :type data_dir: str\n",
    "    :return: DataFrame procesado.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    file_path = data_dir + \"Stressed_Tweets.csv\"\n",
    "\n",
    "    df_stressed = pd.read_csv(file_path)\n",
    "    df_stressed['priority'] = [1 for _ in range(df_stressed.shape[0])]\n",
    "    df_stressed.rename(columns={'cleaned_text': 'text'}, inplace=True)\n",
    "    df_stressed.dropna(inplace=True)\n",
    "\n",
    "    return df_stressed.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment140 - 1,6M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:02:09.794064Z",
     "start_time": "2023-05-14T17:02:04.760197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 2)\n"
     ]
    }
   ],
   "source": [
    "df_sentiment = pd.read_csv(DATA_DIR + \"training.1600000.processed.noemoticon.csv\", encoding='latin-1', header=None)\n",
    "cols = ['priority', 'text']\n",
    "df_sentiment = df_sentiment[[0, 5]]\n",
    "df_sentiment.columns= ['priority', 'text']\n",
    "df_sentiment.dropna(inplace=True)\n",
    "print(df_sentiment.shape)\n",
    "#  (0 = negative, 2 = neutral, 4 = positive)\n",
    "df_sentiment['priority'] = df_sentiment['priority'].replace([0], 1)\n",
    "df_sentiment['priority'] = df_sentiment['priority'].replace([2, 4], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:02:12.355521Z",
     "start_time": "2023-05-14T17:02:12.332475Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_data['training.1600000.processed.noemoticon.csv'] = df_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anon_Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T02:29:49.147564Z",
     "start_time": "2023-05-10T02:19:58.053238Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_14296\\2142906065.py:1: DtypeWarning: Columns (0,1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_anon_control = pd.read_csv(DATA_DIR + \"anon_control_tweets.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_anon_control = pd.read_csv(DATA_DIR + \"anon_control_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T02:33:33.693035Z",
     "start_time": "2023-05-10T02:29:49.210532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['control' nan]\n"
     ]
    }
   ],
   "source": [
    "df_anon_control = df_anon_control.drop(columns=['Unnamed: 0', 'user_id'], axis=1)\n",
    "print(df_anon_control['disorder'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T02:37:43.619412Z",
     "start_time": "2023-05-10T02:34:50.878118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['control', nan]\n"
     ]
    }
   ],
   "source": [
    "df_anon_control.rename(columns={'disorder': 'priority'}, inplace=True)\n",
    "df_anon_control['priority'] = df_anon_control['priority'].replace(list(df_anon_control['priority'].unique()), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T02:42:29.810117Z",
     "start_time": "2023-05-10T02:37:46.893926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31930059, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anon_control.dropna(inplace=True)\n",
    "df_anon_control.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T02:43:11.027004Z",
     "start_time": "2023-05-10T02:43:11.008891Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_data['anon_control_tweets.csv'] = df_anon_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading previous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:02:24.344377Z",
     "start_time": "2023-05-14T17:02:24.201376Z"
    }
   },
   "outputs": [],
   "source": [
    "prev_data = pd.read_csv(\"../data/text/cleaned/out.csv\")\n",
    "prev_data.rename(columns={'label': 'priority'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:02:26.437791Z",
     "start_time": "2023-05-14T17:02:26.386741Z"
    }
   },
   "outputs": [],
   "source": [
    "prev_data['priority'] = prev_data['priority'].replace([0, 3, 4], 'high')\n",
    "prev_data['priority'] = prev_data['priority'].replace([1, 2, 5, 6], 'low')\n",
    "prev_data['priority'] = prev_data['priority'].replace(['high', 'low'], [1, 0])\n",
    "cleaned_data['out.csv'] = prev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:02:28.728973Z",
     "start_time": "2023-05-14T17:02:28.711898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_data['priority'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apilar todos los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:06:53.211941Z",
     "start_time": "2023-05-14T17:06:53.171942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxious_Tweets.csv\n",
      "dataset.xlsx\n",
      "Lonely_Tweets.csv\n",
      "mental_health.csv\n",
      "Normal_Tweets.csv\n",
      "p_n_n_dataset.csv\n",
      "Stressed_Tweets.csv\n",
      "training.1600000.processed.noemoticon.csv\n",
      "out.csv\n"
     ]
    }
   ],
   "source": [
    "def update_priority_dtype(cleaned_data):\n",
    "    \"\"\"\n",
    "    Actualiza el tipo de datos de la columna 'priority' en cada DataFrame de cleaned_data.\n",
    "\n",
    "    :param cleaned_data: Diccionario que contiene los DataFrames procesados.\n",
    "    :type cleaned_data: dict\n",
    "    \"\"\"\n",
    "    for file, df in cleaned_data.items():\n",
    "        print(file)\n",
    "        df['priority'] = df['priority'].astype('int8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:06:59.029884Z",
     "start_time": "2023-05-14T17:06:58.780383Z"
    }
   },
   "outputs": [],
   "source": [
    "final_dataset = pd.concat(list(cleaned_data.values()), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:07:09.487158Z",
     "start_time": "2023-05-14T17:07:09.437160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1914960, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:07:21.067548Z",
     "start_time": "2023-05-14T17:07:11.831682Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "filepath = Path('../data/text/cleaned/reduced_final.csv')\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "final_dataset.to_csv(filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
