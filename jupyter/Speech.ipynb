{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T11:36:27.111237Z",
     "end_time": "2023-04-21T11:36:27.120504Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Silence elimination"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def eliminar_silencio(ruta_base: str, carpetas: list) -> None:\n",
    "    \"\"\"\n",
    "    Removes the silence from the .wav files in the specified folders and saves the clean files in a new folder called 'clean_audios'.\n",
    "\n",
    "    :param ruta_base: The base path where the folders with the audio files are located.\n",
    "    :type ruta_base: str\n",
    "    :param carpetas: A list with the names of the folders to be processed.\n",
    "    :type carpetas: list\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(\"../data/clean_audios\"):\n",
    "        os.mkdir(\"../data/clean_audios\")\n",
    "\n",
    "    for directorio, subdirectorios, archivos in os.walk(ruta_base):\n",
    "\n",
    "        if os.path.basename(directorio) in carpetas:\n",
    "            for archivo in archivos:\n",
    "                if archivo.endswith(\".wav\"):\n",
    "                    audio, tasa_muestreo = librosa.load(os.path.join(directorio, archivo), sr=None)\n",
    "                    audio_sin_silencio, indices_no_silencio = librosa.effects.trim(audio)\n",
    "                    ruta_limpia = os.path.join(\"../data/clean_audios\", os.path.basename(directorio))\n",
    "                    if not os.path.exists(ruta_limpia):\n",
    "                        os.mkdir(ruta_limpia)\n",
    "                    wavfile.write(os.path.join(ruta_limpia, archivo), tasa_muestreo, audio_sin_silencio)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T11:36:28.712381Z",
     "end_time": "2023-04-21T11:36:28.716653Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43meliminar_silencio\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../data/audios/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43memoreact\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mIemocap\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mravdess\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTESS\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[5], line 21\u001B[0m, in \u001B[0;36meliminar_silencio\u001B[0;34m(ruta_base, carpetas)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m archivo\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.wav\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     20\u001B[0m     audio, tasa_muestreo \u001B[38;5;241m=\u001B[39m librosa\u001B[38;5;241m.\u001B[39mload(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(directorio, archivo), sr\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m---> 21\u001B[0m     audio_sin_silencio, indices_no_silencio \u001B[38;5;241m=\u001B[39m \u001B[43mlibrosa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meffects\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrim\u001B[49m\u001B[43m(\u001B[49m\u001B[43maudio\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     ruta_limpia \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/clean_audios\u001B[39m\u001B[38;5;124m\"\u001B[39m, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(directorio))\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(ruta_limpia):\n",
      "File \u001B[0;32m~/anaconda3/envs/tf24_conda/lib/python3.8/site-packages/librosa/effects.py:516\u001B[0m, in \u001B[0;36mtrim\u001B[0;34m(y, top_db, ref, frame_length, hop_length, aggregate)\u001B[0m\n\u001B[1;32m    468\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrim\u001B[39m(\n\u001B[1;32m    469\u001B[0m     y: np\u001B[38;5;241m.\u001B[39mndarray,\n\u001B[1;32m    470\u001B[0m     \u001B[38;5;241m*\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    475\u001B[0m     aggregate: Callable \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmax,\n\u001B[1;32m    476\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[np\u001B[38;5;241m.\u001B[39mndarray, np\u001B[38;5;241m.\u001B[39mndarray]:\n\u001B[1;32m    477\u001B[0m     \u001B[38;5;124;03m\"\"\"Trim leading and trailing silence from an audio signal.\u001B[39;00m\n\u001B[1;32m    478\u001B[0m \n\u001B[1;32m    479\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    513\u001B[0m \u001B[38;5;124;03m    25.025986394557822 25.007891156462584\u001B[39;00m\n\u001B[1;32m    514\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 516\u001B[0m     non_silent \u001B[38;5;241m=\u001B[39m \u001B[43m_signal_to_frame_nonsilent\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mframe_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhop_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhop_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m        \u001B[49m\u001B[43mref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mref\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtop_db\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtop_db\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m        \u001B[49m\u001B[43maggregate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maggregate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    525\u001B[0m     nonzero \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mflatnonzero(non_silent)\n\u001B[1;32m    527\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m nonzero\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    528\u001B[0m         \u001B[38;5;66;03m# Compute the start and end positions\u001B[39;00m\n\u001B[1;32m    529\u001B[0m         \u001B[38;5;66;03m# End position goes one frame past the last non-zero\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf24_conda/lib/python3.8/site-packages/librosa/effects.py:453\u001B[0m, in \u001B[0;36m_signal_to_frame_nonsilent\u001B[0;34m(y, frame_length, hop_length, top_db, ref, aggregate)\u001B[0m\n\u001B[1;32m    419\u001B[0m \u001B[38;5;124;03m\"\"\"Frame-wise non-silent indicator for audio input.\u001B[39;00m\n\u001B[1;32m    420\u001B[0m \n\u001B[1;32m    421\u001B[0m \u001B[38;5;124;03mThis is a helper function for `trim` and `split`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;124;03m    Indicator of non-silent frames\u001B[39;00m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;66;03m# Compute the MSE for the signal\u001B[39;00m\n\u001B[0;32m--> 453\u001B[0m mse \u001B[38;5;241m=\u001B[39m \u001B[43mfeature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrms\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mframe_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhop_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhop_length\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;66;03m# Convert to decibels and slice out the mse channel\u001B[39;00m\n\u001B[1;32m    456\u001B[0m db \u001B[38;5;241m=\u001B[39m core\u001B[38;5;241m.\u001B[39mamplitude_to_db(mse[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;241m0\u001B[39m, :], ref\u001B[38;5;241m=\u001B[39mref, top_db\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf24_conda/lib/python3.8/site-packages/librosa/feature/spectral.py:887\u001B[0m, in \u001B[0;36mrms\u001B[0;34m(y, S, frame_length, hop_length, center, pad_mode, dtype)\u001B[0m\n\u001B[1;32m    884\u001B[0m     x \u001B[38;5;241m=\u001B[39m util\u001B[38;5;241m.\u001B[39mframe(y, frame_length\u001B[38;5;241m=\u001B[39mframe_length, hop_length\u001B[38;5;241m=\u001B[39mhop_length)\n\u001B[1;32m    886\u001B[0m     \u001B[38;5;66;03m# Calculate power\u001B[39;00m\n\u001B[0;32m--> 887\u001B[0m     power \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(\u001B[43mutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mabs2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    888\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m S \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    889\u001B[0m     \u001B[38;5;66;03m# Check the frame length\u001B[39;00m\n\u001B[1;32m    890\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m S\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m!=\u001B[39m frame_length \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/tf24_conda/lib/python3.8/site-packages/librosa/util/utils.py:2521\u001B[0m, in \u001B[0;36mabs2\u001B[0;34m(x, dtype)\u001B[0m\n\u001B[1;32m   2518\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m y\u001B[38;5;241m.\u001B[39mastype(dtype)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   2519\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2520\u001B[0m     \u001B[38;5;66;03m# suppress type check, mypy doesn't know this is real\u001B[39;00m\n\u001B[0;32m-> 2521\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpower\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "eliminar_silencio(\"../data/audios/\",[\"emoreact\", \"Iemocap\", \"ravdess\", \"TESS\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataframe Creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ravdess"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "ravdess = '../data/clean_audios/ravdess'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T11:38:33.925430Z",
     "end_time": "2023-04-21T11:38:33.934884Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def create_rav_emotion_df(ruta_clean_audios: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a dataframe with two columns: emotion and path, using the emotion label encoded in the file names\n",
    "    of the .wav files in the specified directory.\n",
    "\n",
    "    :param ruta_clean_audios: The path where the clean audio files are located.\n",
    "    :type ruta_clean_audios: str\n",
    "    :return: A pandas dataframe with the emotion label and the path of each file.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # List to store the emotion and path for each file\n",
    "    emotion_paths = []\n",
    "\n",
    "    # Loop through all the .wav files in the specified directory\n",
    "    for root, _, files in os.walk(ruta_clean_audios):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                # Get the emotion label from the file name\n",
    "                emotion_label = int(file[7])\n",
    "\n",
    "                # Assign emotion based on label\n",
    "                if emotion_label == 1 or emotion_label == 2:\n",
    "                    emotion = \"neutral\"\n",
    "                elif emotion_label == 3:\n",
    "                    emotion = \"joy\"\n",
    "                elif emotion_label == 4:\n",
    "                    emotion = \"sadness\"\n",
    "                elif emotion_label == 5 or emotion_label == 7:\n",
    "                    emotion = \"anger\"\n",
    "                elif emotion_label == 6:\n",
    "                    emotion = \"fear\"\n",
    "                elif emotion_label == 8:\n",
    "                    emotion = \"surprise\"\n",
    "\n",
    "                # Create tuple with emotion and path\n",
    "                path = os.path.join(root, file)\n",
    "                emotion_path = (emotion, path)\n",
    "\n",
    "                # Append to list\n",
    "                emotion_paths.append(emotion_path)\n",
    "\n",
    "    # Create pandas dataframe with emotion and path columns\n",
    "    df = pd.DataFrame(emotion_paths, columns=[\"emotion\", \"path\"])\n",
    "\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T11:38:34.627420Z",
     "end_time": "2023-04-21T11:38:34.633421Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "   emotion                                               path\n0  sadness  ../data/clean_audios/ravdess/03-01-04-01-02-02...\n1     fear  ../data/clean_audios/ravdess/03-01-06-02-02-02...\n2      joy  ../data/clean_audios/ravdess/03-01-03-02-01-02...\n3  neutral  ../data/clean_audios/ravdess/03-01-01-01-01-02...\n4  neutral  ../data/clean_audios/ravdess/03-01-02-02-01-02...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sadness</td>\n      <td>../data/clean_audios/ravdess/03-01-04-01-02-02...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fear</td>\n      <td>../data/clean_audios/ravdess/03-01-06-02-02-02...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>joy</td>\n      <td>../data/clean_audios/ravdess/03-01-03-02-01-02...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>neutral</td>\n      <td>../data/clean_audios/ravdess/03-01-01-01-01-02...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neutral</td>\n      <td>../data/clean_audios/ravdess/03-01-02-02-01-02...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ravdess_df=create_rav_emotion_df(ravdess)\n",
    "ravdess_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T11:38:35.730913Z",
     "end_time": "2023-04-21T11:38:35.783324Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iemocap"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "iemocapCsv = '../data/aud_em/iemo.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T11:38:38.358704Z",
     "end_time": "2023-04-21T11:38:38.374847Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def create_path_dataframe(ruta_csv):\n",
    "    \"\"\"\n",
    "    Reads a csv file with a 'path' column that contains file paths in a specific format,\n",
    "    modifies the paths to include the correct folder and replaces the emotion values with\n",
    "    the desired values, then filters out any rows with emotion values that are not in the list\n",
    "    of emotions to consider.\n",
    "\n",
    "    :param ruta_csv: The path of the csv file to read.\n",
    "    :type ruta_csv: str\n",
    "    :return: A pandas dataframe with the modified paths.\n",
    "    :rtype: pandas.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # List of emotions to consider\n",
    "    emotions_to_consider = ['neutral', 'joy', 'sadness', 'anger', 'fear', 'surprise']\n",
    "\n",
    "    # Read the csv file\n",
    "    df = pd.read_csv(ruta_csv)\n",
    "\n",
    "    # Modify the 'path' column\n",
    "    df['path'] = df['path'].apply(lambda x: \"../data/clean_audios/iemocap/\" + x.split(\"/\")[-1])\n",
    "\n",
    "    # Replace the 'emotion' values\n",
    "    df['emotion'] = df['emotion'].replace({'neu': 'neutral', 'fru': 'anger', 'sad': 'sadness', 'sur': 'surprise',\n",
    "                                           'ang': 'anger', 'hap': 'joy', 'exc': 'joy', 'fea': 'fear', 'dis': 'anger'})\n",
    "\n",
    "    # Filter out any rows with emotion values that are not in the list of emotions to consider\n",
    "    df = df[df['emotion'].isin(emotions_to_consider)]\n",
    "\n",
    "    # Select only the 'path' column and return the resulting dataframe\n",
    "    return df[['emotion', 'path']]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T11:38:39.101897Z",
     "end_time": "2023-04-21T11:38:39.107154Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "    emotion                                               path\n0   neutral  ../data/clean_audios/iemocap/Ses01F_script02_1...\n1     anger  ../data/clean_audios/iemocap/Ses01F_script02_1...\n3  surprise  ../data/clean_audios/iemocap/Ses01F_script02_1...\n4   neutral  ../data/clean_audios/iemocap/Ses01F_script02_1...\n6     anger  ../data/clean_audios/iemocap/Ses01F_script02_1...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neutral</td>\n      <td>../data/clean_audios/iemocap/Ses01F_script02_1...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>anger</td>\n      <td>../data/clean_audios/iemocap/Ses01F_script02_1...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>surprise</td>\n      <td>../data/clean_audios/iemocap/Ses01F_script02_1...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neutral</td>\n      <td>../data/clean_audios/iemocap/Ses01F_script02_1...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>anger</td>\n      <td>../data/clean_audios/iemocap/Ses01F_script02_1...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iemocap_df = create_path_dataframe(iemocapCsv)\n",
    "iemocap_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T11:38:39.967147Z",
     "end_time": "2023-04-21T11:38:40.042263Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TESS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "tess = '../data/clean_audios/TESS'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T11:38:41.569670Z",
     "end_time": "2023-04-21T11:38:41.581622Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def create_emotion_path_dataframe(ruta: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a dataframe with two columns: 'emotion' and 'path'. The function reads the names of the .wav files\n",
    "    contained in the directory specified by the path parameter and, based on the presence of certain keywords\n",
    "    within the file name, assigns an emotion value to the 'emotion' column. The 'path' column contains the full path\n",
    "    to the .wav file. Only emotions that are explicitly defined are included in the dataframe.\n",
    "\n",
    "    :param ruta: The path where the .wav files are located.\n",
    "    :type ruta: str\n",
    "    :return: A pandas dataframe with two columns: 'emotion' and 'path'.\n",
    "    :rtype: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    emotions = {'fear': 'fear', 'ps': 'surprise', 'sad': 'sadness', 'angry': 'anger', 'disgust': 'anger', 'happy': 'joy', 'neutral': 'neutral'}\n",
    "    file_paths = [os.path.join(ruta, f) for f in os.listdir(ruta) if f.endswith('.wav')]\n",
    "    data = {'emotion': [], 'path': []}\n",
    "    for path in file_paths:\n",
    "        emotion = None\n",
    "        for word, value in emotions.items():\n",
    "            if word in path.lower():\n",
    "                emotion = value\n",
    "                break\n",
    "        if emotion is not None:\n",
    "            data['emotion'].append(emotion)\n",
    "            data['path'].append(path)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T11:38:42.125719Z",
     "end_time": "2023-04-21T11:38:42.180188Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   emotion                                             path\n0      joy    ../data/clean_audios/TESS/OAF_shall_happy.wav\n1    anger   ../data/clean_audios/TESS/OAF_bite_disgust.wav\n2  neutral  ../data/clean_audios/TESS/YAF_voice_neutral.wav\n3  sadness      ../data/clean_audios/TESS/YAF_raise_sad.wav\n4      joy     ../data/clean_audios/TESS/OAF_calm_happy.wav",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>joy</td>\n      <td>../data/clean_audios/TESS/OAF_shall_happy.wav</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>anger</td>\n      <td>../data/clean_audios/TESS/OAF_bite_disgust.wav</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>neutral</td>\n      <td>../data/clean_audios/TESS/YAF_voice_neutral.wav</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sadness</td>\n      <td>../data/clean_audios/TESS/YAF_raise_sad.wav</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>joy</td>\n      <td>../data/clean_audios/TESS/OAF_calm_happy.wav</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess_df=create_emotion_path_dataframe(tess)\n",
    "tess_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T11:38:42.784793Z",
     "end_time": "2023-04-21T11:38:42.832303Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataframe Fusion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "   emotion                                             path\n0      joy    ../data/clean_audios/TESS/OAF_shall_happy.wav\n1    anger   ../data/clean_audios/TESS/OAF_bite_disgust.wav\n2  neutral  ../data/clean_audios/TESS/YAF_voice_neutral.wav\n3  sadness      ../data/clean_audios/TESS/YAF_raise_sad.wav\n4      joy     ../data/clean_audios/TESS/OAF_calm_happy.wav",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>joy</td>\n      <td>../data/clean_audios/TESS/OAF_shall_happy.wav</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>anger</td>\n      <td>../data/clean_audios/TESS/OAF_bite_disgust.wav</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>neutral</td>\n      <td>../data/clean_audios/TESS/YAF_voice_neutral.wav</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sadness</td>\n      <td>../data/clean_audios/TESS/YAF_raise_sad.wav</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>joy</td>\n      <td>../data/clean_audios/TESS/OAF_calm_happy.wav</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.concat([tess_df, iemocap_df, ravdess_df], ignore_index=True)\n",
    "merged_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T11:39:14.803183Z",
     "end_time": "2023-04-21T11:39:14.808472Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Audio Length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def obtener_duraciones_df(df, column_path: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Receives a pandas dataframe with a 'path' column and returns a tuple with a list of\n",
    "    the durations of every audio file in the path column and the number of audio files found.\n",
    "\n",
    "    :param df: The pandas dataframe with the 'path' column.\n",
    "    :type df: pandas.DataFrame\n",
    "    :param column_path: The name of the column that contains the audio file paths.\n",
    "    :type column_path: str\n",
    "    :return: A tuple with a list of durations and the number of audio files found.\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "\n",
    "    duraciones = []\n",
    "    num_audios = 0\n",
    "\n",
    "    for path in df[column_path]:\n",
    "        if \".wav\" in path:\n",
    "            duracion = librosa.get_duration(filename=path)\n",
    "            duraciones.append(duracion)\n",
    "            num_audios += 1\n",
    "\n",
    "    return duraciones, num_audios\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T14:52:57.011119Z",
     "end_time": "2023-04-21T14:52:57.012756Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9914/187694890.py:19: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n",
      "\tThis alias will be removed in version 1.0.\n",
      "  duracion = librosa.get_duration(filename=path)\n",
      "/tmp/ipykernel_9914/187694890.py:19: FutureWarning: PySoundFile failed. Trying audioread instead.\n",
      "\tAudioread support is deprecated in librosa 0.10.0 and will be removed in version 1.0.\n",
      "  duracion = librosa.get_duration(filename=path)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/clean_audios/iemocap/Ses01F_script02_1_F000.wav'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mLibsndfileError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/envs/tf24_conda/lib/python3.8/site-packages/librosa/core/audio.py:803\u001B[0m, in \u001B[0;36mget_duration\u001B[0;34m(y, sr, S, n_fft, hop_length, center, path, filename)\u001B[0m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mduration  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m sf\u001B[38;5;241m.\u001B[39mSoundFileRuntimeError:\n",
      "File \u001B[0;32m~/anaconda3/envs/tf24_conda/lib/python3.8/site-packages/soundfile.py:467\u001B[0m, in \u001B[0;36minfo\u001B[0;34m(file, verbose)\u001B[0m\n\u001B[1;32m    460\u001B[0m \u001B[38;5;124;03m\"\"\"Returns an object with information about a `SoundFile`.\u001B[39;00m\n\u001B[1;32m    461\u001B[0m \n\u001B[1;32m    462\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    465\u001B[0m \u001B[38;5;124;03m    Whether to print additional information.\u001B[39;00m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 467\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_SoundFileInfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf24_conda/lib/python3.8/site-packages/soundfile.py:412\u001B[0m, in \u001B[0;36m_SoundFileInfo.__init__\u001B[0;34m(self, file, verbose)\u001B[0m\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m=\u001B[39m verbose\n\u001B[0;32m--> 412\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mSoundFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m    413\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mname\n",
      "File \u001B[0;32m~/anaconda3/envs/tf24_conda/lib/python3.8/site-packages/soundfile.py:658\u001B[0m, in \u001B[0;36mSoundFile.__init__\u001B[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001B[0m\n\u001B[1;32m    656\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info \u001B[38;5;241m=\u001B[39m _create_info_struct(file, mode, samplerate, channels,\n\u001B[1;32m    657\u001B[0m                                  \u001B[38;5;28mformat\u001B[39m, subtype, endian)\n\u001B[0;32m--> 658\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode_int\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosefd\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    659\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mset\u001B[39m(mode)\u001B[38;5;241m.\u001B[39missuperset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr+\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseekable():\n\u001B[1;32m    660\u001B[0m     \u001B[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf24_conda/lib/python3.8/site-packages/soundfile.py:1216\u001B[0m, in \u001B[0;36mSoundFile._open\u001B[0;34m(self, file, mode_int, closefd)\u001B[0m\n\u001B[1;32m   1215\u001B[0m     err \u001B[38;5;241m=\u001B[39m _snd\u001B[38;5;241m.\u001B[39msf_error(file_ptr)\n\u001B[0;32m-> 1216\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m LibsndfileError(err, prefix\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError opening \u001B[39m\u001B[38;5;132;01m{0!r}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname))\n\u001B[1;32m   1217\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode_int \u001B[38;5;241m==\u001B[39m _snd\u001B[38;5;241m.\u001B[39mSFM_WRITE:\n\u001B[1;32m   1218\u001B[0m     \u001B[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001B[39;00m\n\u001B[1;32m   1219\u001B[0m     \u001B[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001B[39;00m\n\u001B[1;32m   1220\u001B[0m     \u001B[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001B[39;00m\n",
      "\u001B[0;31mLibsndfileError\u001B[0m: Error opening '../data/clean_audios/iemocap/Ses01F_script02_1_F000.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m durations, num_audios \u001B[38;5;241m=\u001B[39m \u001B[43mobtener_duraciones_df\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmerged_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpath\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of audio files found:\u001B[39m\u001B[38;5;124m\"\u001B[39m, num_audios)\n",
      "Cell \u001B[0;32mIn[25], line 19\u001B[0m, in \u001B[0;36mobtener_duraciones_df\u001B[0;34m(df, column_path)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m path \u001B[38;5;129;01min\u001B[39;00m df[column_path]:\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.wav\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m path:\n\u001B[0;32m---> 19\u001B[0m         duracion \u001B[38;5;241m=\u001B[39m \u001B[43mlibrosa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_duration\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m         duraciones\u001B[38;5;241m.\u001B[39mappend(duracion)\n\u001B[1;32m     21\u001B[0m         num_audios \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf24_conda/lib/python3.8/site-packages/librosa/core/audio.py:812\u001B[0m, in \u001B[0;36mget_duration\u001B[0;34m(y, sr, S, n_fft, hop_length, center, path, filename)\u001B[0m\n\u001B[1;32m    804\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m sf\u001B[38;5;241m.\u001B[39mSoundFileRuntimeError:\n\u001B[1;32m    805\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    806\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPySoundFile failed. Trying audioread instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    807\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124mAudioread support is deprecated in librosa 0.10.0\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    810\u001B[0m             category\u001B[38;5;241m=\u001B[39m\u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    811\u001B[0m         )\n\u001B[0;32m--> 812\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43maudioread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maudio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m fdesc:\n\u001B[1;32m    813\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m fdesc\u001B[38;5;241m.\u001B[39mduration  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    815\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/tf24_conda/lib/python3.8/site-packages/audioread/__init__.py:127\u001B[0m, in \u001B[0;36maudio_open\u001B[0;34m(path, backends)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m BackendClass \u001B[38;5;129;01min\u001B[39;00m backends:\n\u001B[1;32m    126\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 127\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mBackendClass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m DecodeError:\n\u001B[1;32m    129\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf24_conda/lib/python3.8/site-packages/audioread/rawread.py:59\u001B[0m, in \u001B[0;36mRawAudioFile.__init__\u001B[0;34m(self, filename)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, filename):\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fh \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     62\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_file \u001B[38;5;241m=\u001B[39m aifc\u001B[38;5;241m.\u001B[39mopen(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fh)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/clean_audios/iemocap/Ses01F_script02_1_F000.wav'"
     ]
    }
   ],
   "source": [
    "durations, num_audios = obtener_duraciones_df(merged_df, 'path')\n",
    "print(\"Number of audio files found:\", num_audios)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
